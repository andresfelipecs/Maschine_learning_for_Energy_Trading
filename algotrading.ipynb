{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresfelipecs/suena_application_test/blob/master/algotrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQYi-jfzHR2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohYMPE2zHR6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0JcOxFuzHR7"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJdh92pzHR8"
      },
      "outputs": [],
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_auction = pd.read_csv(\"/content/sample_data/auction_data.csv\", sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_auction['Date (WET)'] = pd.to_datetime(df_auction['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_auction['date'] = df_auction['Date (WET)']\n",
        "df_auction.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "\n",
        "# Droping the first row\n",
        "units_auction = df_auction.iloc[0]\n",
        "print(units_auction)\n",
        "\n",
        "df_auction = df_auction.drop(df_auction.index[0])\n",
        "\n",
        "\n",
        "# Showing the data \n",
        "print(df_auction)\n",
        "# print(f'INDEX:  {df_auction.index} \\n')\n",
        "# print(f'TYPE:  {df_auction.dtypes} \\n')\n",
        "# print(f'SHAPE:  {df_auction.shape} \\n')\n",
        "print(f\"COLUMNS: {df_auction.columns} \\n\")\n",
        "\n",
        "# print(f'ROW {df_auction.loc[\"2021-01-01 00:00:00\" ]}')\n",
        "\n",
        "\n",
        "# Converting all the elements in the df_auction dataframe to numerical values, so that the data can be used for numerical computations and visualizations.\n",
        "df_auction = df_auction.apply(pd.to_numeric, errors='coerce')\n",
        "# The errors='coerce' argument is used to handle any elements that can't be converted to numerical values. \n",
        "# When errors='coerce', any non-numerical values will be replaced with NaN (Not a Number) values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46vJPy1MzHSA"
      },
      "outputs": [],
      "source": [
        "df_forecast_inputs = pd.read_csv(\n",
        "            \"/content/sample_data/forecast_inputs.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_forecast_inputs['Date (WET)'] = pd.to_datetime(df_forecast_inputs['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_forecast_inputs.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_forecast_inputs = df_forecast_inputs.iloc[0]\n",
        "print(units_forecast_inputs)\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.drop(df_forecast_inputs.index[0])\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_forecast_inputs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuI7_fbKzHSB"
      },
      "outputs": [],
      "source": [
        "df_system_prices = pd.read_csv(\n",
        "            \"/content/sample_data/system_prices.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_system_prices['Date (WET)'] = pd.to_datetime(df_system_prices['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_system_prices.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_system_prices = df_system_prices.iloc[0]\n",
        "print(units_system_prices)\n",
        "\n",
        "df_system_prices = df_system_prices.drop(df_system_prices.index[0])\n",
        "\n",
        "df_system_prices = df_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_system_prices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ayrPST4ZT5q"
      },
      "source": [
        "# Cleaning and Splitting the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq9T-fJkZXsQ"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.distributions import norm\n",
        "\n",
        "# Filling NaN with mode \n",
        "df_auction.fillna(df_auction.mode().iloc[0], inplace=True)\n",
        "df_forecast_inputs.fillna(df_forecast_inputs.mode().iloc[0], inplace=True)\n",
        "df_system_prices.fillna(df_system_prices.mode().iloc[0], inplace=True)\n",
        "\n",
        "train_auction = df_auction[df_auction.index < '2022-03-01']\n",
        "train_auction = train_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_auction = df_auction[df_auction.index >= '2022-03-01']\n",
        "test_auction = test_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index < '2022-03-01']\n",
        "train_forecast_inputs = train_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index >= '2022-03-01']\n",
        "test_forecast_inputs = test_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_system_prices = df_system_prices[df_system_prices.index < '2022-03-01']\n",
        "train_system_prices = train_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_system_prices = df_system_prices[df_system_prices.index >= '2022-03-01']\n",
        "test_system_prices = test_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Using scaler to normalize ALL the data \n",
        "scaler = StandardScaler()\n",
        "\n",
        "all_data = pd.concat([df_auction, df_forecast_inputs, df_system_prices], axis=1)\n",
        "all_data = all_data.apply(pd.to_numeric, errors='coerce')\n",
        "all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns, index=all_data.index)\n",
        "\n",
        "\n",
        "normalized_train_data = all_data[all_data.index < '2022-03-01']\n",
        "normalized_test_data = all_data[all_data.index >= '2022-03-01']\n",
        "\n",
        "normalized_train_auction = normalized_train_data[df_auction.columns]\n",
        "normalized_test_auction = normalized_test_data[df_auction.columns]\n",
        "\n",
        "normalized_train_forecast_inputs = normalized_train_data[df_forecast_inputs.columns]\n",
        "normalized_test_forecast_inputs = normalized_test_data[df_forecast_inputs.columns]\n",
        "\n",
        "normalized_train_system_prices = normalized_train_data[df_system_prices.columns]\n",
        "normalized_test_system_prices = normalized_test_data[df_system_prices.columns]\n",
        "\n",
        "print(normalized_train_auction)\n",
        "\n",
        "# Making sure there are not NaN or inf values \n",
        "print(f\"train auction null data {train_auction.isnull().sum().sum()}\")\n",
        "print(f\"train auction inf data {np.isinf(train_auction).sum().sum()}\")\n",
        "\n",
        "print(f\"train forecast input null data {train_forecast_inputs.isnull().sum().sum()}\")\n",
        "print(f\"tran forecast input inf data {np.isinf(train_forecast_inputs).sum().sum()}\")\n",
        "\n",
        "\n",
        "print(f\"train system price null data {train_system_prices.isnull().sum().sum()}\")\n",
        "print(f\"traion system price inf data {np.isinf(train_system_prices).sum().sum()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4UGlTAuoevg"
      },
      "source": [
        "# Plotting normalized train forecats inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHWkdEjioj68"
      },
      "outputs": [],
      "source": [
        "fig = px.line(normalized_train_forecast_inputs, x=normalized_train_forecast_inputs.index, y=normalized_train_forecast_inputs.columns)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCtrGu_dn5ST"
      },
      "outputs": [],
      "source": [
        "fig = px.line(normalized_train_system_prices, x=normalized_train_system_prices.index, y=normalized_train_system_prices.columns)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvrzoRKkZcnq"
      },
      "source": [
        "# Checking the shapes of the resulting training and testing sets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLQL6NiZfsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"train_auction shape: \", train_auction.shape)\n",
        "print(\"test_auction shape: \", test_auction.shape)\n",
        "\n",
        "print(\"train_forecast_inputs shape: \", train_forecast_inputs.shape)\n",
        "print(\"test_forecast_inputs shape: \", test_forecast_inputs.shape)\n",
        "\n",
        "print(\"train_system_prices shape: \", train_system_prices.shape)\n",
        "print(\"test_system_prices shape: \", test_system_prices.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJmpPLO2pEN"
      },
      "source": [
        "# Tensor flow: **Neural network**, **model** and **forecast**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HYK8FLu2sa6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Splitting the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenate the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Building the neural network model using TensorFlow\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(train_features.shape[1],)))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Defining callbacks to monitor the training process\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10),\n",
        "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "]\n",
        "\n",
        "# Trainning the model on the training data\n",
        "history = model.fit(train_features, train_target, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "# Using the trained model to make predictions on the train data\n",
        "train_forecast = model.predict(train_features)\n",
        "\n",
        "# Using the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenating the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "test_forecast = model.predict(test_features)\n",
        "\n",
        "print(f\"train forecast {train_forecast.shape}\")\n",
        "print(f\"test forecast {test_forecast.shape}\")\n",
        "\n",
        "# Summary: \n",
        "# The model built using TensorFlow is a sequential neural network type DNN (Deep Neural Network) model, as it consists of multiple densely connected layers of neuron. \n",
        "# The model has three dense layers with 64 neurons in each layer and uses the Rectified Linear Unit (ReLU) activation function\n",
        "# for the first two layers and a linear activation function for the last layer. \n",
        "# The model is trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error loss function. \n",
        "# The model is also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# The trained model is then used to make predictions on the train and test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87qsO0t_YjTc"
      },
      "source": [
        "# Results plot:  **train second auction**, **test second auction**, **train forecast**, **test forecast**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnbjZdJvuxoA"
      },
      "outputs": [],
      "source": [
        "# print(train_forecast)\n",
        "# print(test_forecast)\n",
        "# Creating a dataframe for the train forecast\n",
        "train_forecast_df = pd.DataFrame(train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "test_forecast_df = pd.DataFrame(test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFUTJ2i7hB2"
      },
      "source": [
        "# Plotting train **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIQSXK5j3THY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_forecast_df.index,\n",
        "                y=train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Normalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILWIQbp07om-"
      },
      "source": [
        "# Plotting normalized test **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehbc7nlp7vdW"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_forecast_df.index,\n",
        "                y=test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Normalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm0jaSi9ZgDb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Denormalizing the train forecast\n",
        "train_forecast_df['price_second_auction_forecast'] = train_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "# Denormalizing the test forecast\n",
        "test_forecast_df['price_second_auction_forecast'] = test_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "\n",
        "print(f\"train forecast df : {train_forecast_df['price_second_auction_forecast']}\")\n",
        "print(f\"test forecast df {test_forecast_df['price_second_auction_forecast']}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbDHL_W8kaXX"
      },
      "source": [
        "#  Denormalized Plots: (Results) (train **prices** and **volume**) (test **prices** and **volume**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYYqIgNorFOD"
      },
      "outputs": [],
      "source": [
        "# print(train_auction)\n",
        "# print(test_auction)\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_auction.index, y=train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.5)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_auction.index, y=test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.5)))\n",
        "\n",
        "fig.update_layout(title='Denormalized Train and Test Forecasts Second Auction ')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeqI9bwaBIE6"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_forecast_df.index,\n",
        "                y=train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Denormalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItxmpoBbB6fB"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_forecast_df.index,\n",
        "                y=test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Denormalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor flow: predictions with Kfold validations"
      ],
      "metadata": {
        "id": "3jg57MthRdAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenate the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Define the number of folds for the K-fold cross-validation\n",
        "n_folds = 5\n",
        "\n",
        "# Initialize a KFold object with the number of folds\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
        "\n",
        "# Initialize arrays to store the results of the cross-validation\n",
        "cv_scores = []\n",
        "cv_histories = []\n",
        "\n",
        "# Loop over the folds\n",
        "for train_idx, val_idx in kfold.split(train_features):\n",
        "    # Split the data into training and validation sets for each fold\n",
        "    x_train, x_val = train_features[train_idx], train_features[val_idx]\n",
        "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
        "    \n",
        "    # Build the neural network model using TensorFlow\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Define callbacks to monitor the training process\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    # Reshape the data to include a channel dimension\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "\n",
        "    # Train the model on the training data for each fold\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "    # Evaluate the model on the validation data for each fold\n",
        "    score = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "    # Append the results of the fold to the arrays\n",
        "    cv_scores.append(score)\n",
        "    cv_histories.append(history)\n",
        "\n",
        "# Calculate the average performance of the model across all folds\n",
        "mean_score = np.mean(cv_scores, axis=0)\n",
        "\n",
        "# Print the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "# Use the trained model to make predictions on the train data\n",
        "validated_train_forecast = model.predict(train_features)\n",
        "\n",
        "print(validated_train_forecast)\n",
        "print(validated_train_forecast.shape)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenate the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "validated_test_forecast = model.predict(test_features)\n",
        "\n",
        "\n",
        "# Summary: \n",
        "# The model being used is a 1D Convolutional Neural Network (CNN) built using TensorFlow. \n",
        "# It has multiple layers, including two 1D convolutional layers, two max pooling layers, a flatten layer, two dense layers, and a dropout layer. \n",
        "# It's trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error (MSE) loss function. \n",
        "# It's also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# Performming K-fold cross-validation, where the data is split into training and validation sets for each fold, and the model is trained and evaluated on each fold. \n",
        "# Finally, the trained model is used to make predictions on the train and test data.\n",
        "\n",
        "# Decided to change the model to CNN, one most commonly used for time series forecasting to validate and compare results with the previous model.\n",
        "# It is also recommended to do K-fold cross-validation in order to have a better performace estimation, reduce overfitting and helps us identifying \n",
        "# the model stability. If the performance scores low variability across different folds, it suggests that the model may perform well on unseen data.\n"
      ],
      "metadata": {
        "id": "hGXyhmthgpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance scores"
      ],
      "metadata": {
        "id": "fmeeFT69ZKvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the mean and standard deviation of the target variable\n",
        "target_mean = np.mean(normalized_train_auction['price_second_auction'])\n",
        "target_std = np.std(normalized_train_auction['price_second_auction'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Target Mean: \", target_mean)\n",
        "print(\"Target Standard Deviation: \", target_std)\n",
        "\n",
        "# Print the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "# Based on the performance metrics, the model is performing relatively well. \n",
        "# The average loss value of 0.064 and mean absolute error value of 0.107 \n",
        "# It indicates that the model is making predictions that are relatively close to the true values, \n",
        "# with an average absolute difference of approximately 0.11 between the predicted and true values.\n"
      ],
      "metadata": {
        "id": "oeC8CGwfYL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results plot: Plotting validated normalized values "
      ],
      "metadata": {
        "id": "-T5lsVEqQkO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdlR8rJ9QibW"
      },
      "outputs": [],
      "source": [
        "print(validated_train_forecast)\n",
        "print(validated_test_forecast)\n",
        "\n",
        "# Creating a dataframe for the train forecast\n",
        "validated_train_forecast_df = pd.DataFrame(validated_train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "validated_test_forecast_df = pd.DataFrame(validated_test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.Timestamp('2022-02-28 23:00:00')\n",
        "end_date = pd.Timestamp('2022-09-12 23:00:00')\n",
        "\n",
        "# Calculate the number of hours between start_date and end_date\n",
        "n_hours = (end_date - start_date).total_seconds() / 3600\n",
        "\n",
        "print(\"Number of hours between start and end dates:\", n_hours)\n",
        "\n"
      ],
      "metadata": {
        "id": "0FEVgWonvfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    # Create a new DataFrame with necessary columns\n",
        "    future_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return future_features\n",
        "\n",
        "\n",
        "# Define the number of steps to forecast\n",
        "n_steps = 10176\n",
        "\n",
        "# Concatenate the shifted feature datasets with the original feature datasets\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# Autoencoder\n",
        "input_shape = train_features.shape[1]\n",
        "input_layer = Input(shape=(input_shape,))\n",
        "encoder_layer = Dense(26, activation='relu')(input_layer)\n",
        "decoder_layer = Dense(input_shape, activation='linear')(encoder_layer)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder_layer)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(train_features, train_features, epochs=100, batch_size=32)\n",
        "\n",
        "# Create an encoder model using the trained autoencoder\n",
        "encoder = Model(inputs=input_layer, outputs=encoder_layer)\n",
        "\n",
        "# Prepare the input data for the future predictions\n",
        "future_inputs = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# Use the encoder to extract features from the input data\n",
        "encoded_future_inputs = encoder.predict(future_inputs)\n",
        "\n",
        "# Build the neural network model using TensorFlow\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(26, 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model on the encoded training data\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "# Prepare future_features for prediction\n",
        "future_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# Use the encoder to extract features from the future_inputs\n",
        "encoded_future_features = encoder.predict(future_features)\n",
        "\n",
        "# Reshape the data to include a channel dimension\n",
        "encoded_future_features = encoded_future_features.reshape(encoded_future_features.shape[0], encoded_future_features.shape[1], 1)\n",
        "\n",
        "# Predict the future prices using the trained model\n",
        "future_forecast = model.predict(encoded_future_features)\n",
        "\n",
        "print(\"Predicted future values shape:\", future_forecast.shape)\n",
        "\n",
        "forecast_dates = pd.date_range(start='2022-02-28 23:00:00', periods=future_forecast.shape[0], freq='H')\n",
        "\n",
        "future_forecast_df = pd.DataFrame(future_forecast, columns=['predicted_price'], index=forecast_dates)\n",
        "\n",
        "print(future_forecast_df)\n",
        "print(future_forecast_df.columns)\n"
      ],
      "metadata": {
        "id": "e9O8dUk1-aO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7po-797VqG"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df.index, y=future_forecast_df['predicted_price'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lgGD2y7-hZO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRADING ALGORITHM"
      ],
      "metadata": {
        "id": "Chl_6A9XaTk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def price_first_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Calculates the winning price and traded volume for each hour in a sealed bid auction.\n",
        "    In a sealed bid auction, all bids are submitted simultaneously and the highest bid wins.\n",
        "\n",
        "    Parameters:\n",
        "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
        "    \"\"\"\n",
        "    winning_prices = []\n",
        "    traded_volumes = []\n",
        "    for hourly_bids in bids:\n",
        "        if hourly_bids:\n",
        "            winning_price = max(bid[1] for bid in hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] == winning_price)\n",
        "            traded_volumes.append(traded_volume)\n",
        "        else:\n",
        "            winning_prices.append(0)\n",
        "            traded_volumes.append(0)\n",
        "    return (winning_prices, traded_volumes)\n",
        "\n",
        "def price_second_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Calculates the winning price and traded volume for each hour in a pay-as-bid auction.\n",
        "    In a pay-as-bid auction, bids are submitted one by one, and the current winning price is set to the highest bid so far.\n",
        "\n",
        "    Parameters:\n",
        "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
        "    \"\"\"\n",
        "    winning_prices = []\n",
        "    traded_volumes = []\n",
        "    for hourly_bids in bids:\n",
        "        if hourly_bids:\n",
        "            winning_price = max(bid[1] for bid in hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] >= winning_price)\n",
        "            traded_volumes.append(traded_volume)\n",
        "        else:\n",
        "            winning_prices.append(0)\n",
        "            traded_volumes.append(0)\n",
        "    return (winning_prices, traded_volumes)\n",
        "\n",
        "\n",
        "bids = [[(10, 20), (20, 30), (30, 25), (25, 20)]]\n",
        "\n",
        "winning_prices_first_auction = price_first_auction(bids)[0]\n",
        "traded_volumes_first_auction = price_first_auction(bids)[1]\n",
        "print(f\"Winning prices first auction : {winning_prices_first_auction}\")\n",
        "print(f\"Traded volumes first auction{traded_volumes_first_auction}\")\n",
        "\n",
        "winning_prices_second_auction = price_second_auction(bids)[0]\n",
        "traded_volumes_second_auction = price_second_auction(bids)[1]\n",
        "print(f\"Winning prices second auction : {winning_prices_second_auction}\")\n",
        "print(f\"Traded volumes second auction{traded_volumes_second_auction}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "W84WOK1ramEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}