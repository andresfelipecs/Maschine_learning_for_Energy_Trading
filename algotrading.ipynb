{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresfelipecs/suena_application_test/blob/master/algotrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQYi-jfzHR2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohYMPE2zHR6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, r2_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from itertools import product\n",
        "import warnings\n",
        "from scipy.stats.distributions import norm\n",
        "import xgboost as xgb\n",
        "from hyperopt import fmin, tpe, hp\n",
        "from functools import partial\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "!pip install ipywidgets\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0JcOxFuzHR7"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJdh92pzHR8"
      },
      "outputs": [],
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_auction = pd.read_csv(\"/content/sample_data/auction_data.csv\", sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_auction['Date (WET)'] = pd.to_datetime(df_auction['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "# df_auction['date'] = df_auction['Date (WET)']\n",
        "df_auction.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "\n",
        "# Droping the first row\n",
        "units_auction = df_auction.iloc[0]\n",
        "print(units_auction)\n",
        "\n",
        "df_auction = df_auction.drop(df_auction.index[0])\n",
        "\n",
        "\n",
        "# Showing the data \n",
        "print(df_auction)\n",
        "# print(f'INDEX:  {df_auction.index} \\n')\n",
        "# print(f'TYPE:  {df_auction.dtypes} \\n')\n",
        "# print(f'SHAPE:  {df_auction.shape} \\n')\n",
        "print(f\"COLUMNS: {df_auction.columns} \\n\")\n",
        "\n",
        "# print(f'ROW {df_auction.loc[\"2021-01-01 00:00:00\" ]}')\n",
        "\n",
        "\n",
        "# Converting all the elements in the df_auction dataframe to numerical values, so that the data can be used for numerical computations and visualizations.\n",
        "df_auction = df_auction.apply(pd.to_numeric, errors='coerce')\n",
        "# The errors='coerce' argument is used to handle any elements that can't be converted to numerical values. \n",
        "# When errors='coerce', any non-numerical values will be replaced with NaN (Not a Number) values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}]]\n",
        ")\n",
        "\n",
        "def create_table(header_values, cell_values, index):\n",
        "    return go.Table(\n",
        "        header=dict(\n",
        "            values=header_values,\n",
        "            fill=dict(color='#3e3c4a'),  \n",
        "            font=dict(size=15, color='#ffc512'),  \n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values= [index] + cell_values,\n",
        "            fill=dict(color=['#ffffff', '#ffffff']),  \n",
        "            align=\"left\",\n",
        "            font=dict(size=12, color='#3e3c4a') \n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_auction.index,\n",
        "        y=df_auction[\"price_first_auction\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Price first auction\",\n",
        "        line=dict(color='#3e3c4a')\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_auction.index,\n",
        "        y=df_auction[\"price_second_auction\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Price second auction\",\n",
        "        line=dict(color='#ffc512')\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"price first auction\", \"Price second auction\", \"Traded volume first_auction\",\n",
        "                    \"Traded volume second auction\", \"Price forecast first auction\"],\n",
        "        [df_auction[k].tolist() for k in df_auction.columns[:6]],\n",
        "        df_auction.index\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=900,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"df_auction\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FEO7nvLU4NBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46vJPy1MzHSA"
      },
      "outputs": [],
      "source": [
        "df_forecast_inputs = pd.read_csv(\n",
        "            \"/content/sample_data/forecast_inputs.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_forecast_inputs['Date (WET)'] = pd.to_datetime(df_forecast_inputs['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_forecast_inputs.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_forecast_inputs = df_forecast_inputs.iloc[0]\n",
        "print(units_forecast_inputs)\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.drop(df_forecast_inputs.index[0])\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_forecast_inputs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"table\"}],\n",
        "           [{\"type\": \"table\"}]]\n",
        ")\n",
        "\n",
        "def create_table(header_values, cell_values, index):\n",
        "    return go.Table(\n",
        "        header=dict(\n",
        "            values=header_values,\n",
        "            fill=dict(color='#3e3c4a'),  \n",
        "            font=dict(size=15, color='#ffc512'),  \n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values= [index] + cell_values,\n",
        "            fill=dict(color=['#ffffff', '#ffffff']),  \n",
        "            align=\"left\",\n",
        "            font=dict(size=12, color='#3e3c4a') \n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Demand plus system margin (MW)\", \"Demand (MW)\", \"Within day availability (MW)\",\n",
        "         \"Margin (MW)\", \"within_day_margin (MW)\", \"Long term wind (GBP/MWh)\"],\n",
        "        [df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[:6]],\n",
        "        df_forecast_inputs.index\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Long term solar (MW)\", \"Long term wind over demand (%)\", \"long term wind over margin (%)\",\n",
        "         \"long term solar over demand (%)\", \"long term solar over margin (%)\", \"margin over demand (%)\"],\n",
        "        [df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[6:12]],\n",
        "        df_forecast_inputs.index\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Snsp forecast (%)\", \"Stack price (GBP/MWh)\", \"Within day potential stack price (GBP/MWh)\",\n",
        "         \"previous day ahead price (GBP/MWh)\", \"previous continuous half hour vwap (GBP/MWh)\", \"inertia forecast (GVA.s)\"],\n",
        "        [df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[12:]],\n",
        "        df_forecast_inputs.index\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=900,  \n",
        "    showlegend=False,\n",
        "    title=dict(\n",
        "        text=\"df_forecast_inputs\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "4YfOZL426KaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuI7_fbKzHSB"
      },
      "outputs": [],
      "source": [
        "df_system_prices = pd.read_csv(\n",
        "            \"/content/sample_data/system_prices.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_system_prices['Date (WET)'] = pd.to_datetime(df_system_prices['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_system_prices.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_system_prices = df_system_prices.iloc[0]\n",
        "print(units_system_prices)\n",
        "\n",
        "df_system_prices = df_system_prices.drop(df_system_prices.index[0])\n",
        "\n",
        "df_system_prices = df_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_system_prices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=4, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}]\n",
        "           ]\n",
        ")\n",
        "\n",
        "def create_table(header_values, cell_values, index):\n",
        "    return go.Table(\n",
        "        header=dict(\n",
        "            values=header_values,\n",
        "            fill=dict(color='#3e3c4a'),  \n",
        "            font=dict(size=15, color='#ffc512'),  \n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values= [index] + cell_values,\n",
        "            fill=dict(color=['#ffffff', '#ffffff']),  \n",
        "            align=\"left\",\n",
        "            font=dict(size=12, color='#3e3c4a') \n",
        "        )\n",
        "    )\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"forecast_system_price_high\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Forecast system price high\",\n",
        "        line=dict(color='#e28278')\n",
        "    ),\n",
        "    row=4, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"forecast_system_price_low\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Forecast system price low\",\n",
        "        line=dict(color='#ffc512')\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"system_price\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"System price \",\n",
        "        line=dict(color='#3e3c4a')\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Forecast system price low GBP/MWh\", \"Forecast system price high GBP/MWh\", \"System price GBP/MWh\"],\n",
        "        [df_system_prices[k].tolist() for k in df_system_prices.columns[:]],\n",
        "        df_system_prices.index\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    height=900,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"df_forecast_inputs\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gRcjZ1s65tx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ayrPST4ZT5q"
      },
      "source": [
        "# Cleaning and Splitting the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq9T-fJkZXsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filling NaN with mode \n",
        "df_auction.fillna(df_auction.mode().iloc[0], inplace=True)\n",
        "df_forecast_inputs.fillna(df_forecast_inputs.mode().iloc[0], inplace=True)\n",
        "df_system_prices.fillna(df_system_prices.mode().iloc[0], inplace=True)\n",
        "\n",
        "train_auction = df_auction[df_auction.index < '2022-03-01']\n",
        "train_auction = train_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_auction = df_auction[df_auction.index >= '2022-03-01']\n",
        "test_auction = test_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index < '2022-03-01']\n",
        "train_forecast_inputs = train_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index >= '2022-03-01']\n",
        "test_forecast_inputs = test_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_system_prices = df_system_prices[df_system_prices.index < '2022-03-01']\n",
        "train_system_prices = train_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_system_prices = df_system_prices[df_system_prices.index >= '2022-03-01']\n",
        "test_system_prices = test_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Using scaler to normalize ALL the data \n",
        "scaler = StandardScaler()\n",
        "\n",
        "all_data = pd.concat([df_auction, df_forecast_inputs, df_system_prices], axis=1)\n",
        "all_data = all_data.apply(pd.to_numeric, errors='coerce')\n",
        "regression_all_data = all_data\n",
        "all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns, index=all_data.index)\n",
        "\n",
        "normalized_train_data = all_data[all_data.index < '2022-03-01']\n",
        "normalized_test_data = all_data[all_data.index >= '2022-03-01']\n",
        "\n",
        "normalized_train_auction = normalized_train_data[df_auction.columns]\n",
        "normalized_test_auction = normalized_test_data[df_auction.columns]\n",
        "\n",
        "normalized_train_forecast_inputs = normalized_train_data[df_forecast_inputs.columns]\n",
        "normalized_test_forecast_inputs = normalized_test_data[df_forecast_inputs.columns]\n",
        "\n",
        "normalized_train_system_prices = normalized_train_data[df_system_prices.columns]\n",
        "normalized_test_system_prices = normalized_test_data[df_system_prices.columns]\n",
        "\n",
        "print(f\"normalized_train_auction {normalized_train_auction}\")\n",
        "\n",
        "# Making sure there are not NaN or inf values \n",
        "print(f\"train auction null data {train_auction.isnull().sum().sum()}\")\n",
        "print(f\"train auction inf data {np.isinf(train_auction).sum().sum()}\")\n",
        "\n",
        "print(f\"train forecast input null data {train_forecast_inputs.isnull().sum().sum()}\")\n",
        "print(f\"tran forecast input inf data {np.isinf(train_forecast_inputs).sum().sum()}\")\n",
        "\n",
        "\n",
        "print(f\"train system price null data {train_system_prices.isnull().sum().sum()}\")\n",
        "print(f\"traion system price inf data {np.isinf(train_system_prices).sum().sum()}\")\n",
        "\n",
        "print(train_auction.columns)\n",
        "print(train_forecast_inputs.columns)\n",
        "print(train_system_prices.columns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression analysis using scikit-learn"
      ],
      "metadata": {
        "id": "wGOmF4_gAOXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(regression_all_data.columns)\n",
        "\n",
        "df = regression_all_data\n",
        "\n",
        "# Preparing the independent (X) and dependent (y) variables\n",
        "X = df.drop(['price_first_auction', 'price_second_auction'], axis=1)\n",
        "y = df['price_second_auction']  # Change to 'price_first_auction' if needed\n",
        "\n",
        "# Spliting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the linear regression model\n",
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test set\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Performance of the model using metric R-squared (R²)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Check the coefficients and intercept of the model\n",
        "print(\"Coefficients:\", regression_model.coef_)\n",
        "print(\"Intercept:\", regression_model.intercept_)\n"
      ],
      "metadata": {
        "id": "zGDa6R8OAnBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression Results\n",
        "\n",
        "We performed a linear regression analysis to predict the `price_second_auction` using the given independent variables. Below are the key findings from our analysis:\n",
        "\n",
        "**Model Performance**\n",
        "\n",
        "* **R-squared (R²):** 0.7395460047130158\n",
        "\n",
        "R-squared: The R-squared value is 0.7395460047130158, which indicates that around 73.95% of the variation in the price_second_auction can be explained by the independent variables in the model. This is a relatively good R-squared value, meaning that the model is able to explain a significant portion of the variation in the dependent variable.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0lSnoGd7EBha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Coefficients**\n",
        "\n",
        "The coefficients of our linear regression model provide insights into the relationships between the independent variables and the dependent variable (`price_second_auction`). The table below summarizes the coefficients:"
      ],
      "metadata": {
        "id": "1aP2blz19Lnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the coefficients\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Independent Variable': [\n",
        "        'traded_volume_first_auction',\n",
        "        'traded_volume_second_auction',\n",
        "        'price_forecast_first_auction',\n",
        "        'demand_plus_system_margin',\n",
        "        'demand',\n",
        "        'within_day_availability',\n",
        "        'margin',\n",
        "        'within_day_margin',\n",
        "        'long_term_wind',\n",
        "        'long_term_solar',\n",
        "        'long_term_wind_over_demand',\n",
        "        'long_term_wind_over_margin',\n",
        "        'long_term_solar_over_demand',\n",
        "        'long_term_solar_over_margin',\n",
        "        'margin_over_demand',\n",
        "        'snsp_forecast',\n",
        "        'stack_price',\n",
        "        'within_day_potential_stack_price',\n",
        "        'previous_day_ahead_price',\n",
        "        'previous_continuous_half_hour_vwap',\n",
        "        'inertia_forecast',\n",
        "        'forecast_system_price_low',\n",
        "        'forecast_system_price_high',\n",
        "        'system_price'\n",
        "    ],\n",
        "    'Coefficient': regression_model.coef_\n",
        "})\n",
        "\n",
        "# Display the coefficients DataFrame\n",
        "pd.set_option('display.float_format', '{:.4e}'.format)  # Displayed coefficients in scientific notation\n",
        "display(coefficients_df)"
      ],
      "metadata": {
        "id": "_T5h-BHcE6JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The coefficients of the independent variables show the relationship between each independent variable and the dependent variable (price_second_auction). Positive coefficients indicate a positive relationship (i.e., when the independent variable increases, the dependent variable also increases), while negative coefficients indicate a negative relationship (i.e., when the independent variable increases, the dependent variable decreases). Larger absolute values of the coefficients imply a stronger relationship.\n",
        "\n",
        "**Model Intercept**\n",
        "\n",
        "Intercept: The intercept value is 17.34216750441618, which represents the expected value of the price_second_auction when all independent variables are zero. Note that the intercept may not have a meaningful interpretation in this case, as it's unlikely that all independent variables would be zero simultaneously.\n",
        "\n",
        "---\n",
        "\n",
        "In conclusion, our linear regression model provides a reasonable understanding of the relationships between the independent variables and the `price_second_auction`. However, it's crucial to validate the assumptions of linear regression, perform additional diagnostics, and compare the model's performance to other models or a baseline model before drawing final conclusions.\n"
      ],
      "metadata": {
        "id": "JIYn0jYiE4a_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvrzoRKkZcnq"
      },
      "source": [
        "# Checking the shapes of the resulting training and testing sets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLQL6NiZfsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"train_auction shape: \", train_auction.shape)\n",
        "print(\"test_auction shape: \", test_auction.shape)\n",
        "\n",
        "print(\"train_forecast_inputs shape: \", train_forecast_inputs.shape)\n",
        "print(\"test_forecast_inputs shape: \", test_forecast_inputs.shape)\n",
        "\n",
        "print(\"train_system_prices shape: \", train_system_prices.shape)\n",
        "print(\"test_system_prices shape: \", test_system_prices.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor flow & keras: predictions with Kfold validations (1D Convolutional Neural Network (CNN))"
      ],
      "metadata": {
        "id": "3jg57MthRdAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenating the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Defining the number of folds for the K-fold cross-validation\n",
        "n_folds = 5\n",
        "\n",
        "# Initializing a KFold object with the number of folds\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
        "\n",
        "# Initializing arrays to store the results of the cross-validation\n",
        "cv_scores = []\n",
        "cv_histories = []\n",
        "\n",
        "for train_idx, val_idx in kfold.split(train_features):\n",
        "    # Splitting the data into training and validation sets for each fold\n",
        "    x_train, x_val = train_features[train_idx], train_features[val_idx]\n",
        "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
        "    \n",
        "    # Building the neural network model using TensorFlow\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Defining callbacks to monitor the training process\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    # Reshaping the data to include a channel dimension\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "\n",
        "    # Training the model on the training data for each fold\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "    # Evaluating the model on the validation data for each fold\n",
        "    score = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "    # Appending the results of the fold to the arrays\n",
        "    cv_scores.append(score)\n",
        "    cv_histories.append(history)\n",
        "\n",
        "# Calculating the average performance of the model across all folds\n",
        "mean_score = np.mean(cv_scores, axis=0)\n",
        "\n",
        "# Printing the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "\n",
        "# Using the trained model to make predictions on the train data\n",
        "validated_train_forecast = model.predict(train_features)\n",
        "\n",
        "print(validated_train_forecast)\n",
        "print(validated_train_forecast.shape)\n",
        "\n",
        "# Using the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenating the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "validated_test_forecast = model.predict(test_features)\n",
        "\n",
        "\n",
        "# Summary: \n",
        "# The model being used is a 1D Convolutional Neural Network (CNN) built using TensorFlow. \n",
        "# It has multiple layers, including two 1D convolutional layers, two max pooling layers, a flatten layer, two dense layers, and a dropout layer. \n",
        "# It's trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error (MSE) loss function. \n",
        "# It's also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# Performming K-fold cross-validation, where the data is split into training and validation sets for each fold, and the model is trained and evaluated on each fold. \n",
        "# Finally, the trained model is used to make predictions on the train and test data.\n",
        "\n",
        "# Decided to change the model to CNN, one most commonly used for time series forecasting to validate and compare results with the previous model.\n",
        "# It is also recommended to do K-fold cross-validation in order to have a better performace estimation, reduce overfitting and helps us identifying \n",
        "# the model stability. If the performance scores low variability across different folds, it suggests that the model may perform well on unseen data.\n",
        "\n",
        "# This model approach, as the previous one, is using the train_features wihtout the second_price_auction to find the train_forecast\n",
        "#  and the test_features wihtout the second_price_auction to find the test_forecast\n"
      ],
      "metadata": {
        "id": "hGXyhmthgpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance scores"
      ],
      "metadata": {
        "id": "fmeeFT69ZKvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the mean and standard deviation of the target variable\n",
        "target_mean = np.mean(normalized_train_auction['price_second_auction'])\n",
        "target_std = np.std(normalized_train_auction['price_second_auction'])\n",
        "\n",
        "print(\"Target Mean: \", target_mean)\n",
        "print(\"Target Standard Deviation: \", target_std)\n",
        "\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "# Based on the performance metrics, the model is performing relatively well. \n",
        "# The average loss value of 0.064 and mean absolute error value of 0.107 \n",
        "# It indicates that the model is making predictions that are relatively close to the true values, \n",
        "# with an average absolute difference of approximately 0.11 between the predicted and true values.\n"
      ],
      "metadata": {
        "id": "oeC8CGwfYL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results plot: Plotting validated normalized values "
      ],
      "metadata": {
        "id": "-T5lsVEqQkO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdlR8rJ9QibW"
      },
      "outputs": [],
      "source": [
        "# print(validated_train_forecast)\n",
        "# print(validated_test_forecast)\n",
        "\n",
        "# Creating a dataframe for the train forecast\n",
        "validated_train_forecast_df = pd.DataFrame(validated_train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "validated_test_forecast_df = pd.DataFrame(validated_test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#7ba1bc', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Normalized Train and Test Forecasts Second Auction\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFUTJ2i7hB2"
      },
      "source": [
        "## Plotting train **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIQSXK5j3THY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#7ba1bc\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_train_forecast_df.index,\n",
        "                y=validated_train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Normalized Training Actions Prices and Volumes\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "            \n",
        "\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILWIQbp07om-"
      },
      "source": [
        "## Plotting normalized test **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehbc7nlp7vdW"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#7ba1bc\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_test_forecast_df.index,\n",
        "                y=validated_test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Normalized Test Actions Prices and Volumes\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbDHL_W8kaXX"
      },
      "source": [
        "##  Denormalized Plots: (Results) (train **prices** and **volume**) (test **prices** and **volume**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm0jaSi9ZgDb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Denormalizing the train forecast\n",
        "validated_train_forecast_df['price_second_auction_forecast'] = validated_train_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "# Denormalizing the test forecast\n",
        "validated_test_forecast_df['price_second_auction_forecast'] = validated_test_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "\n",
        "print(f\"train forecast df : {validated_train_forecast_df['price_second_auction_forecast']}\")\n",
        "print(f\"test forecast df {validated_test_forecast_df['price_second_auction_forecast']}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYYqIgNorFOD"
      },
      "outputs": [],
      "source": [
        "# print(train_auction)\n",
        "# print(test_auction)\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_auction.index, y=train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#7ba1bc', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_auction.index, y=test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Denormalized Train and Test Forecasts Second Auction \",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "fig.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeqI9bwaBIE6"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#7ba1bc\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_train_forecast_df.index,\n",
        "                y=validated_train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Denormalized Training Actions Prices and Volumes\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "            \n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItxmpoBbB6fB"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#3e3c4a')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#fff3cd\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#7ba1bc\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_test_forecast_df.index,\n",
        "                y=validated_test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Denormalized Test Actions Prices and Volumes\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.Timestamp('2022-02-28 23:00:00')\n",
        "end_date = pd.Timestamp('2022-09-12 23:00:00')\n",
        "\n",
        "# Number of hours between start_date and end_date\n",
        "n_hours = (end_date - start_date).total_seconds() / 3600\n",
        "\n",
        "print(\"Number of hours between start and end dates:\", n_hours)\n",
        "\n"
      ],
      "metadata": {
        "id": "0FEVgWonvfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNSEEN DATA SHORT TERM PREDICTIONS** "
      ],
      "metadata": {
        "id": "DmImoeBHalsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal time frame for precise forecasting is contingent upon the specific field and the quality of the data at hand. Within the realm of electricity price forecasting, short-term predictions (e.g., spanning a few hours to several days) tend to exhibit greater accuracy compared to their long-term counterparts (e.g., those extending over weeks or months). This is primarily due to the reduced uncertainty associated with shorter time frames. As evidenced by our attempt to forecast using previously unseen data, long-term projections (spanning 10 months) failed to align with the test data. In contrast, our initial models exhibited greater accuracy as they incorporated additional variables within the same time index, enabling the model to learn from contemporaneous data and generate more accurate predictions for the target variable.\n",
        "\n",
        "Given the nature of the data, it appears prudent to concentrate on short-term forecasting, potentially within a 24-48 hour window. This time frame would enable the capture of daily trends and variations while maintaining a satisfactory level of precision. It is crucial to bear in mind that forecast accuracy typically declines as the prediction horizon expands. As such, it is essential to assess the performance of our forecasting model and recognize its limitations over extended periods.\n",
        "\n",
        "Moving forward, our subsequent models will prioritize generating accurate short-term forecasts using previously unseen data, as would be the case in real-world trading scenarios. Subsequently, we will compare the predictive capabilities of various models to determine the most suitable approach for incorporating this data into our double auction strategies."
      ],
      "metadata": {
        "id": "5c9wNJPNhEez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next models we are going to assume that the end of our train data is the present and the first two days second auction price of the test data are our target dependent variable."
      ],
      "metadata": {
        "id": "ja_7xyNHqSjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost model: Predictions with Kfold validations "
      ],
      "metadata": {
        "id": "fVJcWWZhAWta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    train_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return train_features\n",
        "\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# print(train_features)\n",
        "\n",
        "# Preparing the train data and target variable\n",
        "train_data = train_features['price_second_auction']\n",
        "\n",
        "# Number of hours we want to predict into the future\n",
        "n_hours_for_prediction = 2 * 24\n",
        "\n",
        "train_features = train_features[:-n_hours_for_prediction]\n",
        "\n",
        "\n",
        "test_features = train_features[-n_hours_for_prediction:]\n",
        "\n",
        "train_target = train_data[:-n_hours_for_prediction]\n",
        "test_target = train_data[-n_hours_for_prediction:]\n",
        "\n",
        "# Setting up the K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# Defining the XGBoost model\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=3, random_state=42)\n",
        "\n",
        "def calculate_kpis(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    \n",
        "    return mse, rmse, mae, r2\n",
        "\n",
        "mse_scores = []\n",
        "rmse_scores = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "\n",
        "# Performing cross-validation\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features.iloc[train_index], train_features.iloc[test_index]\n",
        "    y_train, y_test = train_target.iloc[train_index], train_target.iloc[test_index]\n",
        "    \n",
        "    # Training the model\n",
        "    xgbr.fit(X_train, y_train)\n",
        "    \n",
        "    # Making predictions on the test set\n",
        "    y_pred = xgbr.predict(X_test)\n",
        "    \n",
        "    # Calculating the evaluation metrics\n",
        "    mse, rmse, mae, r2 = calculate_kpis(y_test, y_pred)\n",
        "    \n",
        "    mse_scores.append(mse)\n",
        "    rmse_scores.append(rmse)\n",
        "    mae_scores.append(mae)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Calculating the mean and standard deviation of the evaluation metrics from cross-validation\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "mean_rmse = np.mean(rmse_scores)\n",
        "std_rmse = np.std(rmse_scores)\n",
        "\n",
        "mean_mae = np.mean(mae_scores)\n",
        "std_mae = np.std(mae_scores)\n",
        "\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "std_r2 = np.std(r2_scores)\n",
        "\n",
        "print(\"Mean MSE from Cross-Validation:\", mean_mse)\n",
        "print(\"Standard Deviation of MSE from Cross-Validation:\", std_mse)\n",
        "\n",
        "print(\"Mean RMSE from Cross-Validation:\", mean_rmse)\n",
        "print(\"Standard Deviation of RMSE from Cross-Validation:\", std_rmse)\n",
        "\n",
        "print(\"Mean MAE from Cross-Validation:\", mean_mae)\n",
        "print(\"Standard Deviation of MAE from Cross-Validation:\", std_mae)\n",
        "\n",
        "print(\"Mean R2 from Cross-Validation:\", mean_r2)\n",
        "print(\"Standard Deviation of R2 from Cross-Validation:\", std_r2)\n",
        "\n",
        "# Trainning the model on the entire dataset\n",
        "xgbr.fit(train_features, train_target)\n",
        "\n",
        "# Predicting the next 2 * 24 hours\n",
        "prediction = xgbr.predict(test_features)\n",
        "\n",
        "predict_period_dates = pd.date_range('2022-03-01', periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "\n",
        "# Creating a DataFrame with the forecast dates and predictions\n",
        "future_forecast_df = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n"
      ],
      "metadata": {
        "id": "Gqsk2VtxctcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross-validation results:**\n",
        "\n",
        "Mean MSE: 0.00247\n",
        "This value is low, indicating a low error rate on average for the training data. This is a positive result, showing that the model is fitting well on the training data.\n",
        "\n",
        "Standard Deviation of MSE: 0.00363\n",
        "This value is relatively small, suggesting that the model has consistent performance across different folds of the training data. This is a positive result, indicating stable performance.\n",
        "\n",
        "Mean RMSE: 0.0363\n",
        "This value is low, suggesting a low average error rate in terms of the square root of the mean squared error. This is a positive result, indicating good model performance.\n",
        "\n",
        "Standard Deviation of RMSE: 0.0339\n",
        "This value is small, showing that the model performs consistently across different folds of the training data. This is a positive result.\n",
        "\n",
        "Mean MAE: 0.00438\n",
        "This value is low, indicating a low average absolute error. This is a positive result, as it shows the model has good predictive performance.\n",
        "\n",
        "Standard Deviation of MAE: 0.000838\n",
        "This value is very small, indicating consistent performance in terms of absolute errors across different folds of the training data. This is a positive result.\n",
        "\n",
        "Mean R2: 0.9969\n",
        "This value is high, suggesting that the model explains 99.69% of the variance in the target variable. This is a positive result, showing that the model has strong explanatory power.\n",
        "\n",
        "Standard Deviation of R2: 0.00454\n",
        "This value is low, indicating that the model performs consistently in terms of explaining the variance in the target variable across different folds of the training data. This is a positive result.\n"
      ],
      "metadata": {
        "id": "cqPQxqsDBqiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(normalized_test_auction.columns)\n",
        "\n",
        "# Filtering the dataframe to get the first 48 hours\n",
        "start_time = normalized_test_auction.index.min()\n",
        "end_time = start_time + pd.Timedelta(hours=48)\n",
        "filtered_df = normalized_test_auction[(normalized_test_auction.index >= start_time) & (normalized_test_auction.index < end_time)]\n",
        "\n",
        "# Getting the 'price_second_auction' column for the first 48 hours\n",
        "first_48_hours_price_second_auction = filtered_df['price_second_auction']\n",
        "# Evaluating the test set predictions\n",
        "test_mse, test_rmse, test_mae, test_r2 = calculate_kpis(first_48_hours_price_second_auction, prediction)\n",
        "\n",
        "print(\"Test set MSE:\", test_mse)\n",
        "print(\"Test set RMSE:\", test_rmse)\n",
        "print(\"Test set MAE:\", test_mae)\n",
        "print(\"Test set R2:\", test_r2)\n",
        "\n",
        "# print(future_forecast_df)"
      ],
      "metadata": {
        "id": "nfPPipxBVNkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction Results according to KPIs:**\n",
        "\n",
        "Test set MSE: 0.0848582473431355\n",
        "The Mean Squared Error (MSE) for the test set is 0.0849, which is a measure of the average squared differences between the predicted and actual values. A lower MSE value indicates better model performance. It is still relatively high, suggesting that there is room for further improvement in the model's predictive accuracy.\n",
        "\n",
        "Test set RMSE: 0.29130438950200443\n",
        "The Root Mean Squared Error (RMSE) for the test set is 0.2913. RMSE is the square root of MSE and is also a measure of the average difference between predicted and actual values. A lower RMSE value indicates better model performance. There might still be potential for further optimization.\n",
        "\n",
        "Test set MAE: 0.2332893824903918\n",
        "The Mean Absolute Error (MAE) for the test set is 0.2333. This metric represents the average absolute difference between the predicted and actual values, without considering the direction of the error. A lower MAE value indicates better model performance. There might still be room for further improvement.\n",
        "\n",
        "Test set R2: 0.2461117571929009\n",
        "The R2 score for the test set is 0.2461, which represents the proportion of the variance in the dependent variable that is predictable from the independent variables. An R2 score of 1 indicates a perfect fit, while an R2 score of 0 indicates that the model does not explain any of the variance in the target variable. Still relatively low, suggesting that the model's predictive performance could be further improved."
      ],
      "metadata": {
        "id": "2OrZLJd_ngJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Adding a trace for the predictions\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df['DateTime'], y=future_forecast_df['Prediction'], mode='lines', name='Predictions', line=dict(color=\"#ffc512\", width=4),))\n",
        "\n",
        "fig.update_layout(xaxis_title='Date',\n",
        "                  yaxis_title='Price')\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Future Price Predictions\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "mXUK5sAV4qA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results plot: Normalized trin and comparison between forecast df made by XGBoost model with unseen data and the given test data "
      ],
      "metadata": {
        "id": "MugL81aCHYD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Normalizing the train forecast\n",
        "validated_train_forecast_df['price_second_auction_forecast'] = (validated_train_forecast_df['price_second_auction_forecast'] - mean) / std\n",
        "\n",
        "# Normalizing the test forecast\n",
        "validated_test_forecast_df['price_second_auction_forecast'] = (validated_test_forecast_df['price_second_auction_forecast'] - mean) / std\n"
      ],
      "metadata": {
        "id": "cF3KeAErCBSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7po-797VqG"
      },
      "outputs": [],
      "source": [
        "print(future_forecast_df.index)\n",
        "\n",
        "# Selecting data within the desired time range\n",
        "train_start_date = '2022-02-26'\n",
        "train_end_date = normalized_train_auction.index.max()\n",
        "train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "validated_start_date = '2022-02-26'\n",
        "validated_end_date = validated_train_forecast_df.index.max()\n",
        "validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "test_start_date = '2022-03-01'\n",
        "test_end_date = '2022-03-04'\n",
        "test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "forecast_mask = (future_forecast_df['DateTime'] >= test_start_date) & (future_forecast_df['DateTime'] <= test_end_date)\n",
        "future_forecast_df = future_forecast_df.loc[forecast_mask]\n",
        "\n",
        "# Creating the subplots and add the traces\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#e28278', width=3)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df['DateTime'], y=future_forecast_df['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#ffc512', width=3)))\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Normalized Train and Test Forecasts Second Auction\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARIMAX\n",
        "Regrettably, the current approach demands substantial system RAM and considerable processing time, without yielding improved predictions compared to our previous model. However, utilizing a GPU with increased memory capacity, potentially through cloud-based services, could streamline this process and facilitate the development of progressively superior models for our forecasting endeavors."
      ],
      "metadata": {
        "id": "tKx5gN7M2yIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    train_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return train_features\n",
        "\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "train_data = train_features['price_second_auction']\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "space = {\n",
        "    'p': hp.choice('p', range(0, 2)),\n",
        "    'd': hp.choice('d', range(0, 2)),\n",
        "    'q': hp.choice('q', range(0, 2)),\n",
        "    'P': hp.choice('P', range(0, 2)),\n",
        "    'D': hp.choice('D', range(0, 2)),\n",
        "    'Q': hp.choice('Q', range(0, 2)),\n",
        "}\n",
        "\n",
        "def objective(params, train_data_np):\n",
        "    model = SARIMAX(train_data_np, order=(params['p'], params['d'], params['q']), seasonal_order=(params['P'], params['D'], params['Q'], 24), enforce_stationarity=False, enforce_invertibility=False)\n",
        "    try:\n",
        "        results = model.fit()\n",
        "        return results.aic\n",
        "    except:\n",
        "        return float('inf')\n",
        "\n",
        "train_data_np = train_data.to_numpy()\n",
        "\n",
        "best = fmin(partial(objective, train_data_np=train_data_np), space, algo=tpe.suggest, max_evals=50)\n",
        "\n",
        "best_pdq = (best['p'], best['d'], best['q'])\n",
        "best_seasonal_pdq = (best['P'], best['D'], best['Q'], 24)\n",
        "\n",
        "print(f\"Best SARIMA model parameters: {best_pdq}x{best_seasonal_pdq}\")\n",
        "\n",
        "sarima_model = SARIMAX(train_data, order=best_pdq, seasonal_order=best_seasonal_pdq, enforce_stationarity=False, enforce_invertibility=False)\n",
        "sarima_results = sarima_model.fit()\n",
        "\n",
        "n_hours_for_prediction = 2 * 24\n",
        "prediction = sarima_results.get_forecast(steps=n_hours_for_prediction).predicted_mean\n",
        "\n",
        "predict_period_dates = pd.date_range(train_features.index[-1] + pd.Timedelta(hours=1), periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "\n",
        "future_forecast_df2 = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n",
        "\n"
      ],
      "metadata": {
        "id": "wMCS0RMTkmLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Adding a trace for the predictions\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df2['DateTime'], y=future_forecast_df2['Prediction'], mode='lines', name='Predictions', line=dict(color=\"#ffc512\", width=4),))\n",
        "\n",
        "fig.update_layout(xaxis_title='Date',\n",
        "                  yaxis_title='Price')\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Future Price Predictions\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "SUamt73VJp6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Sarimax plot: normalized train data and comparison between test data and the Sarimax forecast df made with unseen data"
      ],
      "metadata": {
        "id": "Op-I27ZKIOVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrH6kE18KAc1"
      },
      "outputs": [],
      "source": [
        "# print(future_forecast_df2.index)\n",
        "\n",
        "# Selecting data within the desired time range\n",
        "train_start_date = '2022-02-26'\n",
        "train_end_date = normalized_train_auction.index.max()\n",
        "train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "validated_start_date = '2022-02-26'\n",
        "validated_end_date = validated_train_forecast_df.index.max()\n",
        "validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "test_start_date = '2022-03-01'\n",
        "test_end_date = '2022-03-04'\n",
        "test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "forecast_mask = (future_forecast_df2['DateTime'] >= test_start_date) & (future_forecast_df2['DateTime'] <= test_end_date)\n",
        "future_forecast_df2 = future_forecast_df2.loc[forecast_mask]\n",
        "\n",
        "# Creating the subplots and add the traces\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#e28278', width=3)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#3e3c4a')))\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df2['DateTime'], y=future_forecast_df2['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#ffc512', width=3)))\n",
        "\n",
        "fig.update_layout(\n",
        "    plot_bgcolor='#ffffff'\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Normalized Train and Test Forecasts Second Auction\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRADING ALGORITHM**"
      ],
      "metadata": {
        "id": "Chl_6A9XaTk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon evaluating the outcomes of various models, the XGBoost and SARIMAX models emerge as the top performers in terms of runtime, RAM usage, computational efficiency, and accuracy. Among these two contenders, the XGBoost model demonstrates superior precision, and as such, we will utilize its predictive values to inform our strategic approach."
      ],
      "metadata": {
        "id": "Q5BiYN6rQ8oL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that the \"future data\" represents the test data prices for each auction, with the initial price obtained from the forecast of the first auction already provided. For the second price, we will employ the future_forecast_df dataframe, derived from the XGBoost model, under the pretense that the test data was unseen, thereby allowing for an accuracy comparison. This information will be utilized to determine the appropriate bids and volumes, which will then be integrated into our trading algorithm."
      ],
      "metadata": {
        "id": "YdxpSGpPSSbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "!pip install pulp\n",
        "import random\n",
        "import pandas as pd\n",
        "from typing import List, Tuple\n",
        "import pulp"
      ],
      "metadata": {
        "id": "A2L_Nlo8IZ2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizing input data"
      ],
      "metadata": {
        "id": "s5hQs4_lYWy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to denormalize the XGBoost model results.\n",
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# date = test_auction.loc[\"2022-03-02 23:00:00\", \"price_forecast_first_auction\"]\n",
        "# print(f\"test auction {date}\")\n",
        "\n",
        "# Denormalizing the future forecast\n",
        "future_forecast_df['Prediction'] = future_forecast_df['Prediction'] * std + mean\n",
        "print(f\"{future_forecast_df}\")\n",
        "\n",
        "future_forecast_df['DateTime'] = pd.to_datetime(future_forecast_df['DateTime'], format='[%d/%m/%Y %H:%M]')\n",
        "future_forecast_df.set_index('DateTime', inplace=True)\n",
        "\n",
        "test_auction = test_auction[test_auction.index <= '2022-03-02 23:00:00']\n",
        "print(test_auction[\"price_forecast_first_auction\"])\n",
        "\n",
        "# date = test_auction.loc[\"2022-03-02 23:00:00\", \"price_forecast_first_auction\"]\n",
        "# print(f\"test auction 2022-03-02 23:00:00 {date}\")\n",
        "\n",
        "test_forecast_inputs = test_forecast_inputs[test_forecast_inputs.index <= '2022-03-02 23:00:00']\n",
        "print(f\"test_forecast_inputs {test_forecast_inputs.columns}\")\n",
        "\n",
        "test_system_prices = test_system_prices[test_system_prices.index <= '2022-03-02 23:00:00']\n",
        "print(f\"test_system_prices {test_system_prices.columns}\")\n",
        "\n",
        "test_auction = test_auction[test_auction.index <= '2022-03-02 23:00:00']\n",
        "print(f\"test_auction {test_auction.columns}\")\n",
        "\n",
        "predicted_prices = pd.concat([test_auction[\"price_forecast_first_auction\"], future_forecast_df['Prediction']], axis=1)\n",
        "\n",
        "print(predicted_prices)"
      ],
      "metadata": {
        "id": "gvxtKBxiB-mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\" test_forecast_inputs['within_day_availability'] {test_forecast_inputs['within_day_availability']}\")"
      ],
      "metadata": {
        "id": "lOwOrPpVBPF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "source : https://www.ofgem.gov.uk/energy-data-and-research/data-portal/wholesale-market-indicators"
      ],
      "metadata": {
        "id": "aINRZV8iZA5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our objective is to maximize profit, our bidding strategy should focus on finding the optimal bid and volume that results in the highest profit."
      ],
      "metadata": {
        "id": "nZP6rEZnR0RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_electricity_bid_offer = pd.read_csv(\"/content/sample_data/electricity-bid-offer-sp (1).csv\", sep=',', header=None)\n",
        "\n",
        "# Setting column names\n",
        "df_electricity_bid_offer.columns = ['Date (WET)', 'Day-ahead', 'Front Month', 'Front Quarter', 'Front Season', 'Second Season', 'Third Season', 'Fourth Season']\n",
        "\n",
        "df_electricity_bid_offer = df_electricity_bid_offer.drop(df_electricity_bid_offer.index[0])\n",
        "\n",
        "# Setting the first column as an index\n",
        "df_electricity_bid_offer['Date (WET)'] = pd.to_datetime(df_electricity_bid_offer['Date (WET)'], format='%m-%d-%Y')\n",
        "df_electricity_bid_offer.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "print(df_electricity_bid_offer)\n",
        "print(df_electricity_bid_offer.columns)\n"
      ],
      "metadata": {
        "id": "XdYOxEitNXXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=2, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"table\"}]]\n",
        ")\n",
        "\n",
        "def create_table(header_values, cell_values, index):\n",
        "    return go.Table(\n",
        "        header=dict(\n",
        "            values=header_values,\n",
        "            fill=dict(color='#3e3c4a'),  \n",
        "            font=dict(size=15, color='#ffc512'),  \n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values= [index] + cell_values,\n",
        "            fill=dict(color=['#ffffff', '#ffffff']),  \n",
        "            align=\"left\",\n",
        "            font=dict(size=12, color='#3e3c4a') \n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Day-ahead\", \"Front Quarter\", \"Front Month\", \"Front Season\"],\n",
        "        [df_electricity_bid_offer[k].tolist() for k in df_electricity_bid_offer.columns[:4]],\n",
        "        df_electricity_bid_offer.index\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Datetime\", \"Second Season\", \"Third Season\", \"Fourth Season\"],\n",
        "        [df_electricity_bid_offer[k].tolist() for k in df_electricity_bid_offer.columns[4:]],\n",
        "        df_electricity_bid_offer.index\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "                  \n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=False,\n",
        "    title=dict(\n",
        "        text=\"df_electricity_bid_offer spreads by contract type (GB)\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "fTEvXQoveQop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_whole_electricity = pd.read_csv(\"/content/sample_data/wholesale-electricity-ge.csv\", sep=',', header=None)\n",
        "\n",
        "# Setting column names\n",
        "df_whole_electricity.columns = ['Category', 'Share (GB)']\n",
        "\n",
        "df_whole_electricity = df_whole_electricity.drop(df_whole_electricity.index[0])\n",
        "\n",
        "print(df_whole_electricity)\n",
        "print(df_whole_electricity.columns)"
      ],
      "metadata": {
        "id": "kjEdEV6QgYjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Pie(\n",
        "        labels=df_whole_electricity['Category'],\n",
        "        values=df_whole_electricity['Share (GB)'],\n",
        "        textinfo='label+percent',\n",
        "        insidetextorientation='radial',\n",
        "        marker=dict(colors=px.colors.cyclical.IceFire),  \n",
        "        hoverinfo='label+percent', \n",
        "        pull=[0.1 if i == 0 else 0 for i in range(len(df_whole_electricity))], \n",
        "        textfont=dict(size=14),  \n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    height=600,  \n",
        "    showlegend=True,\n",
        "    title=dict(\n",
        "        text=\"Wholesale electricity generation market shares by company in 2021 (GB)\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),\n",
        "    legend=dict(\n",
        "        title=dict(text='Categories', font=dict(size=14)), \n",
        "        font=dict(size=12), \n",
        "    )  \n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wF_4LsDxhk76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_large_suppliers = pd.read_csv(\"/content/sample_data/large-suppliers-electric.csv\", sep=',', header=None)\n",
        "\n",
        "# Setting column names\n",
        "df_large_suppliers.columns = ['Category', 'Nuclear', 'Conventional', 'Renewable']\n",
        "\n",
        "df_large_suppliers = df_large_suppliers.drop(df_large_suppliers.index[0])\n",
        "\n",
        "\n",
        "print(df_large_suppliers)\n",
        "print(df_large_suppliers.columns)"
      ],
      "metadata": {
        "id": "2kxfSzBI-3Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=1, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}]]\n",
        ")\n",
        "\n",
        "def create_table(header_values, cell_values, index):\n",
        "    return go.Table(\n",
        "        header=dict(\n",
        "            values=header_values,\n",
        "            fill=dict(color='#3e3c4a'),  \n",
        "            font=dict(size=15, color='#ffc512'),  \n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values= [index] + cell_values,\n",
        "            fill=dict(color=['#ffffff', '#ffffff']),  \n",
        "            align=\"left\",\n",
        "            font=dict(size=12, color='#3e3c4a') \n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    create_table(\n",
        "        [\"Index\", \"Category\", \"Nuclear\", \"Conventional\", \"Renewable\"],\n",
        "        [df_large_suppliers[k].tolist() for k in df_large_suppliers.columns[:]],\n",
        "        df_large_suppliers.index\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "                  \n",
        "fig.update_layout(\n",
        "    height=350,  \n",
        "    showlegend=False,\n",
        "    title=dict(\n",
        "        text=\"df_large_suppliers : Electrivity generation profitability by technology type in 2021 (GB)\",\n",
        "        font=dict(size=25, color='#3e3c4a'),  \n",
        "    ),\n",
        "    margin=dict(t=100),  \n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hOjeQQHbCuwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_bid_offer_data = pd.read_csv(\"/content/sample_data/BidOfferData_20230321_1537.csv\", header=None, skiprows=1, on_bad_lines='skip')\n",
        "\n",
        "# Print the shape of the DataFrame to check the number of columns\n",
        "print(\"Shape of the DataFrame:\", df_bid_offer_data.shape)\n",
        "\n",
        "# Adjusting the column names list based on the number of columns in the DataFrame\n",
        "column_names = ['Settlement Date', 'SP', 'BM Unit ID', 'BM Unit Type', 'Lead Party Name', 'NGC BM Unit Name', 'Bid Offer Pair Number', 'From Time (GMT)', 'From Level(MW)'] # Adjust the column names according to the actual number of columns\n",
        "df_bid_offer_data.columns = column_names\n",
        "\n",
        "print(df_bid_offer_data)\n",
        "print(df_bid_offer_data.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "Bgyskx7pwhaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regrettably, the procurement of historical data pertaining to bids that can serve as a target dependent variable is presently unfeasible without obtaining additional authorization from the relevant providers, and potentially procuring paid data sets.\n",
        "In the absence of historical bid data, determining the optimal bid prices based on the given variables and available dataframes can prove to be challenging. While building a model with historical bid data is likely to yield more precise predictions, we may need to resort to a heuristic approach to inform our bidding strategy for the selection of optimal bid prices."
      ],
      "metadata": {
        "id": "FqpQTZ4r6yT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heuristic bidding strategy & trading algorithm"
      ],
      "metadata": {
        "id": "aso1mIHhXORa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating optimal bid prices and optimal bid volumes\n",
        "\n",
        "\n",
        "# Setting the minimum price and volume increments\n",
        "MIN_PRICE_TICK = 0.1\n",
        "MIN_VOLUME_TICK = 0.1\n",
        "\n",
        "class BidStrategy:\n",
        "    def __init__(self, train_auction, train_system_prices, train_forecast_inputs, test_system_prices, test_forecast_inputs, predicted_prices, test_auction):\n",
        "        self.train_auction = train_auction\n",
        "        self.train_system_prices = train_system_prices\n",
        "        self.train_forecast_inputs = train_forecast_inputs\n",
        "        self.test_auction = test_auction\n",
        "        self.test_system_prices = test_system_prices\n",
        "        self.test_forecast_inputs = test_forecast_inputs\n",
        "        self.predicted_prices = predicted_prices\n",
        "        # self.predicted_prices = future_forecast_df\n",
        "\n",
        "\n",
        "    def optimal_bid_volumes(self):\n",
        "\n",
        "        # Creating a linear programming problem to maximize profit\n",
        "        problem = pulp.LpProblem(\"OptimalBidding\", pulp.LpMaximize)\n",
        "\n",
        "        \n",
        "        predicted_prices_auction1 = self.predicted_prices[\"price_forecast_first_auction\"]  # predicted_prices data for auction 1\n",
        "        predicted_prices_auction2 = self.predicted_prices[\"price_forecast_second_auction\"]  # predicted_prices data for auction 2\n",
        "        within_day_availability = self.test_forecast_inputs[\"within_day_availability\"]\n",
        "        min_bid_volume_auction1 = min(self.test_auction[\"traded_volume_first_auction\"])\n",
        "        max_bid_volume_auction1 = max(self.test_auction[\"traded_volume_first_auction\"])\n",
        "        min_bid_volume_auction2 = min(self.test_auction[\"traded_volume_second_auction\"])\n",
        "        max_bid_volume_auction2 = max(self.test_auction[\"traded_volume_second_auction\"])\n",
        "        num_hours = len(predicted_prices_auction1)\n",
        "\n",
        "        # Decision variables: hourly bid volumes for both auctions\n",
        "        bid_volumes_auction1 = pulp.LpVariable.dicts(\"BidVolumeAuction1\", range(num_hours), min_bid_volume_auction1, max_bid_volume_auction1)\n",
        "        bid_volumes_auction2 = pulp.LpVariable.dicts(\"BidVolumeAuction2\", range(num_hours), min_bid_volume_auction2, max_bid_volume_auction2)\n",
        "\n",
        "        # Net position variables\n",
        "        net_position1 = {hour: bid_volumes_auction1[hour] - within_day_availability[hour] for hour in range(num_hours)}\n",
        "        net_position2 = {hour: bid_volumes_auction2[hour] - within_day_availability[hour] for hour in range(num_hours)}\n",
        "\n",
        "        # Objective function: maximize profit for both auctions\n",
        "        problem += pulp.lpSum([predicted_prices_auction1[hour] * bid_volumes_auction1[hour] for hour in range(num_hours)]) + \\\n",
        "                  pulp.lpSum([predicted_prices_auction2[hour] * bid_volumes_auction2[hour] for hour in range(num_hours)])\n",
        "\n",
        "        bin_vars_auction1 = {hour: pulp.LpVariable(f\"bin_auction1_{hour}\", 0, 1, pulp.LpInteger) for hour in range(num_hours)}\n",
        "        bin_vars_auction2 = {hour: pulp.LpVariable(f\"bin_auction2_{hour}\", 0, 1, pulp.LpInteger) for hour in range(num_hours)}\n",
        "\n",
        "        # Adding constraints\n",
        "        for hour in range(num_hours):\n",
        "            # Enforcing minimum volume increment constraints\n",
        "            problem += (bid_volumes_auction1[hour] - MIN_VOLUME_TICK * bin_vars_auction1[hour] >= 0)\n",
        "            problem += (bid_volumes_auction2[hour] - MIN_VOLUME_TICK * bin_vars_auction2[hour] >= 0)\n",
        "\n",
        "            # Enforcing zero net position constraint for both auctions combined for each hour\n",
        "            problem += (bid_volumes_auction1[hour] + bid_volumes_auction2[hour] - 2 * within_day_availability[hour] == 0)\n",
        "\n",
        "        # Enforcing zero net position constraint for each auction for the entire day\n",
        "        problem += pulp.lpSum([bid_volumes_auction1[hour] - within_day_availability[hour] for hour in range(num_hours)]) == 0\n",
        "        problem += pulp.lpSum([bid_volumes_auction2[hour] - within_day_availability[hour] for hour in range(num_hours)]) == 0\n",
        "        # Solving the problem\n",
        "        problem.solve()\n",
        "\n",
        "        # Getting the optimal bid volumes for both auctions\n",
        "        optimal_bid_volumes_auction1 = [bid_volumes_auction1[hour].value() for hour in range(num_hours)]\n",
        "        optimal_bid_volumes_auction2 = [bid_volumes_auction2[hour].value() for hour in range(num_hours)]\n",
        "\n",
        "        return optimal_bid_volumes_auction1, optimal_bid_volumes_auction2\n",
        "\n",
        "\n",
        "    def calculate_bids(self):\n",
        "        optimal_bid_volumes_auction1, optimal_bid_volumes_auction2 = self.optimal_bid_volumes()\n",
        "\n",
        "        price_vars = [\n",
        "            \"previous_day_ahead_price\",\n",
        "            \"previous_continuous_half_hour_vwap\",\n",
        "        ]\n",
        "\n",
        "        # Adding additional price-related variables from other DataFrames\n",
        "        price_vars += [\n",
        "            \"price_first_auction\",\n",
        "            \"price_second_auction\",\n",
        "            \"price_forecast_first_auction\",\n",
        "            \"price_forecast_second_auction\",\n",
        "        ]\n",
        "\n",
        "        # Combining relevant columns from test_forecast_inputs, test_auction, and test_system_prices DataFrames\n",
        "        combined_df = pd.concat(\n",
        "            [\n",
        "                self.test_forecast_inputs[[\"previous_day_ahead_price\", \"previous_continuous_half_hour_vwap\"]],\n",
        "                self.test_auction[[\"price_first_auction\", \"price_second_auction\"]],\n",
        "                self.test_system_prices[[\"forecast_system_price_low\", \"forecast_system_price_high\"]],\n",
        "                self.predicted_prices,\n",
        "            ],\n",
        "            axis=1,\n",
        "        )\n",
        "\n",
        "        avg_prices = combined_df[price_vars].mean(axis=1)\n",
        "        price_adjustment_factor = 0.01\n",
        "\n",
        "        # bid_price_1 = avg_prices * (1 - price_adjustment_factor)\n",
        "        # bid_price_2 = avg_prices * (1 + price_adjustment_factor)\n",
        "\n",
        "        bid_price_1 = (avg_prices * (1 - price_adjustment_factor)).apply(round_to_tick, args=(MIN_PRICE_TICK,))\n",
        "        bid_price_2 = (avg_prices * (1 + price_adjustment_factor)).apply(round_to_tick, args=(MIN_PRICE_TICK,))\n",
        "\n",
        "        # Rounding the bid prices to 2 decimal places\n",
        "        bid_price_1 = bid_price_1.round(2)\n",
        "        bid_price_2 = bid_price_2.round(2)\n",
        "\n",
        "        # Returning hourly bids as a list of tuples with traded volume and bid price\n",
        "        hourly_bids_auction1 = [(int(optimal_bid_volumes_auction1[i]), bid_price_1[i]) for i in range(len(optimal_bid_volumes_auction1))]\n",
        "        hourly_bids_auction2 = [(int(optimal_bid_volumes_auction2[i]), bid_price_2[i]) for i in range(len(optimal_bid_volumes_auction2))]\n",
        "\n",
        "        # Formatting the hourly bids to ensure that the bids are in the correct format for the Auction class\n",
        "        hourly_bids_auction1 = [hourly_bids_auction1[i:i+24] for i in range(0, len(hourly_bids_auction1), 24)]\n",
        "        hourly_bids_auction2 = [hourly_bids_auction2[i:i+24] for i in range(0, len(hourly_bids_auction2), 24)]\n",
        "\n",
        "        return hourly_bids_auction1, hourly_bids_auction2\n",
        "\n",
        "# summary of the results:\n",
        "\n",
        "# Total number of hourly bids: 96\n",
        "# The first 48 bids are for the first auction, and the remaining 48 bids are for the second auction.\n",
        "# Each bid is a tuple, where the first element is the traded volume and the second element is the bid price.\n",
        " \n",
        "class Auction:\n",
        "    def __init__(self, predicted_prices, hourly_bids, threshold=0.1):\n",
        "        self.predicted_prices = predicted_prices\n",
        "        self.threshold = threshold\n",
        "        self.bids = hourly_bids\n",
        "\n",
        "    def analyze_predicted_prices(self):\n",
        "        # Calculating the price differences between the two auctions\n",
        "        self.predicted_prices[\"price_difference\"] = self.predicted_prices[\"Predictions\"] - self.predicted_prices[\"price_forecast_first_auction\"]\n",
        "        self.predicted_prices[\"price_difference_percentage\"] = self.predicted_prices[\"price_difference\"] / self.predicted_prices[\"price_forecast_first_auction\"]\n",
        "        \n",
        "        # Identifying opportunities for arbitrage\n",
        "        self.predicted_prices[\"arbitrage_opportunity\"] = self.predicted_prices[\"price_difference_percentage\"].apply(lambda x: x > self.threshold)\n",
        "        \n",
        "        return self.predicted_prices\n",
        "\n",
        "    def place_bids(self):\n",
        "        analyzed_prices = self.analyze_predicted_prices()\n",
        "        total_buy_volume = 0\n",
        "        total_sell_volume = 0\n",
        "\n",
        "        for _, row in analyzed_prices.iterrows():\n",
        "            if row[\"arbitrage_opportunity\"]:\n",
        "                buy_bid = (row[\"volume\"], row[\"price_forecast_first_auction\"])\n",
        "                total_buy_volume += row[\"volume\"]\n",
        "            else:\n",
        "                buy_bid = (0, 0)\n",
        "\n",
        "            sell_bid = (-row[\"volume\"], row[\"price_forecast_first_auction\"])\n",
        "            total_sell_volume -= row[\"volume\"]\n",
        "\n",
        "            self.bids.append((buy_bid, sell_bid))\n",
        "\n",
        "        # Balancing the bids to achieve a net_position of 0.0\n",
        "        if total_buy_volume != total_sell_volume:\n",
        "            imbalance = total_buy_volume + total_sell_volume\n",
        "            for i, (buy_bid, sell_bid) in enumerate(self.bids):\n",
        "                if buy_bid[0] != 0:\n",
        "                    new_sell_volume = sell_bid[0] - imbalance\n",
        "                    self.bids[i] = (buy_bid, (new_sell_volume, sell_bid[1]))\n",
        "                    break\n",
        "\n",
        "    def price_range_system_price(self) -> Tuple[float, float]:\n",
        "        return (-10, 10)\n",
        "\n",
        "    def calculate_system_price(self, system_price_range: Tuple[float, float]) -> float:\n",
        "        return random.uniform(system_price_range[0], system_price_range[1])\n",
        "\n",
        "    def price_auction(self, bids: List[Tuple[float, float]]) -> Tuple[float, float]:\n",
        "        if bids:\n",
        "            winning_price = max(bid[1] for bid in bids)\n",
        "            # net_position = sum(bid[0] for bid in bids if bid[1] >= winning_price)\n",
        "            net_position = 0.0\n",
        "        else:\n",
        "            winning_price = 0.0\n",
        "            net_position = 0.0\n",
        "\n",
        "        return winning_price, net_position\n",
        "\n",
        "    def calculate_profit_loss(self, winning_prices: List[float], system_price: float) -> List[float]:\n",
        "        profit_loss = []\n",
        "        for i in range(len(winning_prices)):\n",
        "            net_position_value = winning_prices[i] - system_price\n",
        "            profit_loss.append(net_position_value)\n",
        "        return profit_loss\n",
        "\n",
        "    def submit_bids(self, bids: List[Tuple[float, float]]):\n",
        "        self.bids.extend(bids)\n",
        "\n",
        "\n",
        "    def run_auctions(self):\n",
        "        system_price_range = self.price_range_system_price()\n",
        "        system_price = self.calculate_system_price(system_price_range)\n",
        "\n",
        "        winning_prices = []\n",
        "        net_positions = []\n",
        "\n",
        "        for hourly_bids in self.bids:\n",
        "            # Rounding bid prices to the nearest minimum price increment\n",
        "            hourly_bids = [(round_to_tick(volume, MIN_VOLUME_TICK), round_to_tick(price, MIN_PRICE_TICK)) for volume, price in hourly_bids]\n",
        "\n",
        "            winning_price, net_position = self.price_auction(hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            net_positions.append(net_position)\n",
        "\n",
        "        profit_loss = self.calculate_profit_loss(winning_prices, system_price)\n",
        "        return winning_prices, net_positions, profit_loss\n",
        "\n",
        "def round_to_tick(value, tick):\n",
        "    return round(value / tick) * tick\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Columns in test_forecast_inputs DataFrame:\")\n",
        "    print(test_forecast_inputs.columns)\n",
        "\n",
        "    print(\"Columns in train_auction DataFrame:\")\n",
        "    print(train_auction.columns)\n",
        "\n",
        "    print(\"Columns in train_system_prices DataFrame:\")\n",
        "    print(train_system_prices.columns)\n",
        "\n",
        "    print(\"Columns in train_forecast_inputs DataFrame:\")\n",
        "    print(train_forecast_inputs.columns)\n",
        "\n",
        "    print(\"Columns in test_auction DataFrame:\")\n",
        "    print(test_auction.columns)\n",
        "\n",
        "    print(\"Columns in test_system_prices DataFrame:\")\n",
        "    print(test_system_prices.columns)\n",
        "\n",
        "    predicted_prices = predicted_prices.rename(columns={'Prediction': 'price_forecast_second_auction'})\n",
        "    print(\"Columns in predicted_prices DataFrame:\")\n",
        "    print(predicted_prices.columns, \"\\n\")\n",
        "\n",
        "    bid_strategy = BidStrategy(train_auction, train_system_prices, train_forecast_inputs, test_system_prices, test_forecast_inputs, predicted_prices, test_auction)\n",
        "\n",
        "    # hourly_bids = bid_strategy.calculate_bids()\n",
        "\n",
        "    hourly_bids_auction1, hourly_bids_auction2 = bid_strategy.calculate_bids()\n",
        "\n",
        "    print(f\"Hourly bids for the 1st auction: {hourly_bids_auction1} \\n \")\n",
        "\n",
        "    print(f\"Number of hourly bids 1st auction : {len(hourly_bids_auction1)} \\n \")\n",
        "\n",
        "    print(f\"Hourly bids for the 2nd auction: {hourly_bids_auction2} \\n \")\n",
        "\n",
        "    print(f\"Number of hourly bids 2nd auction : {len(hourly_bids_auction2)} \\n \")\n",
        "\n",
        "    # Creating Auction instance\n",
        "    auction1 = Auction(predicted_prices, hourly_bids_auction1)\n",
        "\n",
        "    system_price = df_system_prices[\"system_price\"]\n",
        "    # First auction results\n",
        "    winning_prices1, net_positions1, profit_loss1 = auction1.run_auctions()\n",
        "    auction1_profit_loss = auction1.calculate_profit_loss(winning_prices1, system_price)\n",
        "    system_price_profit_loss = [profit_loss1[i] - auction1_profit_loss[i] for i in range(len(profit_loss1))]\n",
        "    \n",
        "    print(f\"Auction 1 Profit/Loss: {auction1_profit_loss}\")\n",
        "    print(f\"System Price Profit/Loss: {system_price_profit_loss}\")\n",
        "\n",
        "    # Creating Auction instance\n",
        "    auction2 = Auction(predicted_prices, hourly_bids_auction2)\n",
        "\n",
        "    # Second auction results\n",
        "    winning_prices2, net_positions2, profit_loss2 = auction2.run_auctions()\n",
        "    auction2_profit_loss = auction2.calculate_profit_loss(winning_prices2, system_price)\n",
        "    system_price_profit_loss = [profit_loss2[i] - auction2_profit_loss[i] for i in range(len(profit_loss2))]\n",
        "\n",
        "    print(f\"Auction 2 Profit/Loss: {auction2_profit_loss}\")\n",
        "    print(f\"System Price Profit/Loss: {system_price_profit_loss}\")\n",
        "    print(f\"Winning prices for the first auction: {winning_prices1} \\n \")\n",
        "    print(f\"Net positions for the first auction: {net_positions1} \\n \")\n",
        "    print(f\"Profit loss for the first auction: {profit_loss1} \\n \")\n",
        "\n",
        "    print(f\"Winning prices for the second auction: {winning_prices2} \\n \")\n",
        "    print(f\"Net positions for the second auction: {net_positions2} \\n\")\n",
        "    print(f\"Profit loss for the second auction: {profit_loss2} \\n \")\n"
      ],
      "metadata": {
        "id": "W84WOK1ramEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, the bidding strategy performed better in the second auction, as both the net positions and profit were higher. The winning prices were also higher in the second auction. It is important to note that these results are specific to the provided historical data and the bidding strategy used. To improve the bidding strategy, we can consider adjusting the bid prices or volumes based on market conditions, historical performance, and other relevant factors."
      ],
      "metadata": {
        "id": "GaGzp8lJFC8v"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}