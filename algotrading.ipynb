{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresfelipecs/suena_application_test/blob/master/algotrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQYi-jfzHR2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohYMPE2zHR6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from itertools import product\n",
        "import warnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0JcOxFuzHR7"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJdh92pzHR8"
      },
      "outputs": [],
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_auction = pd.read_csv(\"/content/sample_data/auction_data.csv\", sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_auction['Date (WET)'] = pd.to_datetime(df_auction['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "# df_auction['date'] = df_auction['Date (WET)']\n",
        "df_auction.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "\n",
        "# Droping the first row\n",
        "units_auction = df_auction.iloc[0]\n",
        "print(units_auction)\n",
        "\n",
        "df_auction = df_auction.drop(df_auction.index[0])\n",
        "\n",
        "\n",
        "# Showing the data \n",
        "print(df_auction)\n",
        "# print(f'INDEX:  {df_auction.index} \\n')\n",
        "# print(f'TYPE:  {df_auction.dtypes} \\n')\n",
        "# print(f'SHAPE:  {df_auction.shape} \\n')\n",
        "print(f\"COLUMNS: {df_auction.columns} \\n\")\n",
        "\n",
        "# print(f'ROW {df_auction.loc[\"2021-01-01 00:00:00\" ]}')\n",
        "\n",
        "\n",
        "# Converting all the elements in the df_auction dataframe to numerical values, so that the data can be used for numerical computations and visualizations.\n",
        "df_auction = df_auction.apply(pd.to_numeric, errors='coerce')\n",
        "# The errors='coerce' argument is used to handle any elements that can't be converted to numerical values. \n",
        "# When errors='coerce', any non-numerical values will be replaced with NaN (Not a Number) values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46vJPy1MzHSA"
      },
      "outputs": [],
      "source": [
        "df_forecast_inputs = pd.read_csv(\n",
        "            \"/content/sample_data/forecast_inputs.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_forecast_inputs['Date (WET)'] = pd.to_datetime(df_forecast_inputs['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_forecast_inputs.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_forecast_inputs = df_forecast_inputs.iloc[0]\n",
        "print(units_forecast_inputs)\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.drop(df_forecast_inputs.index[0])\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_forecast_inputs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuI7_fbKzHSB"
      },
      "outputs": [],
      "source": [
        "df_system_prices = pd.read_csv(\n",
        "            \"/content/sample_data/system_prices.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_system_prices['Date (WET)'] = pd.to_datetime(df_system_prices['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_system_prices.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_system_prices = df_system_prices.iloc[0]\n",
        "print(units_system_prices)\n",
        "\n",
        "df_system_prices = df_system_prices.drop(df_system_prices.index[0])\n",
        "\n",
        "df_system_prices = df_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_system_prices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ayrPST4ZT5q"
      },
      "source": [
        "# Cleaning and Splitting the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq9T-fJkZXsQ"
      },
      "outputs": [],
      "source": [
        "from scipy.stats.distributions import norm\n",
        "\n",
        "# Filling NaN with mode \n",
        "df_auction.fillna(df_auction.mode().iloc[0], inplace=True)\n",
        "df_forecast_inputs.fillna(df_forecast_inputs.mode().iloc[0], inplace=True)\n",
        "df_system_prices.fillna(df_system_prices.mode().iloc[0], inplace=True)\n",
        "\n",
        "train_auction = df_auction[df_auction.index < '2022-03-01']\n",
        "train_auction = train_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_auction = df_auction[df_auction.index >= '2022-03-01']\n",
        "test_auction = test_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index < '2022-03-01']\n",
        "train_forecast_inputs = train_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index >= '2022-03-01']\n",
        "test_forecast_inputs = test_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_system_prices = df_system_prices[df_system_prices.index < '2022-03-01']\n",
        "train_system_prices = train_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_system_prices = df_system_prices[df_system_prices.index >= '2022-03-01']\n",
        "test_system_prices = test_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Using scaler to normalize ALL the data \n",
        "scaler = StandardScaler()\n",
        "\n",
        "all_data = pd.concat([df_auction, df_forecast_inputs, df_system_prices], axis=1)\n",
        "all_data = all_data.apply(pd.to_numeric, errors='coerce')\n",
        "all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns, index=all_data.index)\n",
        "\n",
        "\n",
        "normalized_train_data = all_data[all_data.index < '2022-03-01']\n",
        "normalized_test_data = all_data[all_data.index >= '2022-03-01']\n",
        "\n",
        "normalized_train_auction = normalized_train_data[df_auction.columns]\n",
        "normalized_test_auction = normalized_test_data[df_auction.columns]\n",
        "\n",
        "normalized_train_forecast_inputs = normalized_train_data[df_forecast_inputs.columns]\n",
        "normalized_test_forecast_inputs = normalized_test_data[df_forecast_inputs.columns]\n",
        "\n",
        "normalized_train_system_prices = normalized_train_data[df_system_prices.columns]\n",
        "normalized_test_system_prices = normalized_test_data[df_system_prices.columns]\n",
        "\n",
        "print(normalized_train_auction)\n",
        "\n",
        "# Making sure there are not NaN or inf values \n",
        "print(f\"train auction null data {train_auction.isnull().sum().sum()}\")\n",
        "print(f\"train auction inf data {np.isinf(train_auction).sum().sum()}\")\n",
        "\n",
        "print(f\"train forecast input null data {train_forecast_inputs.isnull().sum().sum()}\")\n",
        "print(f\"tran forecast input inf data {np.isinf(train_forecast_inputs).sum().sum()}\")\n",
        "\n",
        "\n",
        "print(f\"train system price null data {train_system_prices.isnull().sum().sum()}\")\n",
        "print(f\"traion system price inf data {np.isinf(train_system_prices).sum().sum()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4UGlTAuoevg"
      },
      "source": [
        "# Plotting normalized train forecats inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHWkdEjioj68"
      },
      "outputs": [],
      "source": [
        "fig = px.line(normalized_train_forecast_inputs, x=normalized_train_forecast_inputs.index, y=normalized_train_forecast_inputs.columns)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCtrGu_dn5ST"
      },
      "outputs": [],
      "source": [
        "fig = px.line(normalized_train_system_prices, x=normalized_train_system_prices.index, y=normalized_train_system_prices.columns)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvrzoRKkZcnq"
      },
      "source": [
        "# Checking the shapes of the resulting training and testing sets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLQL6NiZfsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"train_auction shape: \", train_auction.shape)\n",
        "print(\"test_auction shape: \", test_auction.shape)\n",
        "\n",
        "print(\"train_forecast_inputs shape: \", train_forecast_inputs.shape)\n",
        "print(\"test_forecast_inputs shape: \", test_forecast_inputs.shape)\n",
        "\n",
        "print(\"train_system_prices shape: \", train_system_prices.shape)\n",
        "print(\"test_system_prices shape: \", test_system_prices.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJmpPLO2pEN"
      },
      "source": [
        "# Tensor flow: **Neural network**, **model** and **forecast** (sequential neural network type DNN (Deep Neural Network) model )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HYK8FLu2sa6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Splitting the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenating the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Building the neural network model using TensorFlow\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(train_features.shape[1],)))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Defining callbacks to monitor the training process\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10),\n",
        "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "]\n",
        "\n",
        "# Trainning the model on the training data\n",
        "history = model.fit(train_features, train_target, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
        "\n",
        "\n",
        "# With this approach we are only focusing on getting the train_forecast with the other variables without the system knowing train_forecast itself\n",
        "# Same approach is done for the test_forecast, in this case using the test_feautures, normalized_test_forecast_inputs, normalized_test_system_prices variables.\n",
        "# Later (ideally) would be trying to get the test_forecast with the train_features only, so it works as real life when we want to predict the future values\n",
        "# That can be done with different approaches, nevertheless complex models need a lot of computation, in that case a paid GPU\n",
        "# might be neccesary to achive better results, to improve model preformance and running time.\n",
        "\n",
        "# Using the trained model to make predictions on the train data\n",
        "train_forecast = model.predict(train_features)\n",
        "\n",
        "# Using the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenating the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "test_forecast = model.predict(test_features)\n",
        "\n",
        "print(f\"train forecast {train_forecast.shape}\")\n",
        "print(f\"test forecast {test_forecast.shape}\")\n",
        "\n",
        "# Summary: \n",
        "# The model built using TensorFlow is a sequential neural network type DNN (Deep Neural Network) model, as it consists of multiple densely connected layers of neuron. \n",
        "# The model has three dense layers with 64 neurons in each layer and uses the Rectified Linear Unit (ReLU) activation function\n",
        "# for the first two layers and a linear activation function for the last layer. \n",
        "# The model is trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error loss function. \n",
        "# The model is also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# The trained model is then used to make predictions on the train and test data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance scores"
      ],
      "metadata": {
        "id": "ZbiFs2y3v0Lh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87qsO0t_YjTc"
      },
      "source": [
        "# Results plot:  **train second auction**, **test second auction**, **train forecast**, **test forecast**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnbjZdJvuxoA"
      },
      "outputs": [],
      "source": [
        "# print(train_forecast)\n",
        "# print(test_forecast)\n",
        "# Creating a dataframe for the train forecast\n",
        "train_forecast_df = pd.DataFrame(train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "test_forecast_df = pd.DataFrame(test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFUTJ2i7hB2"
      },
      "source": [
        "# Plotting train **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIQSXK5j3THY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_forecast_df.index,\n",
        "                y=train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Normalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILWIQbp07om-"
      },
      "source": [
        "# Plotting normalized test **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehbc7nlp7vdW"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_forecast_df.index,\n",
        "                y=test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Normalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm0jaSi9ZgDb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Denormalizing the train forecast\n",
        "train_forecast_df['price_second_auction_forecast'] = train_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "# Denormalizing the test forecast\n",
        "test_forecast_df['price_second_auction_forecast'] = test_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "\n",
        "print(f\"train forecast df : {train_forecast_df['price_second_auction_forecast']}\")\n",
        "print(f\"test forecast df {test_forecast_df['price_second_auction_forecast']}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbDHL_W8kaXX"
      },
      "source": [
        "#  Denormalized Plots: (Results) (train **prices** and **volume**) (test **prices** and **volume**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYYqIgNorFOD"
      },
      "outputs": [],
      "source": [
        "# print(train_auction)\n",
        "# print(test_auction)\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_auction.index, y=train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.5)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_auction.index, y=test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.5)))\n",
        "\n",
        "fig.update_layout(title='Denormalized Train and Test Forecasts Second Auction ')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeqI9bwaBIE6"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_forecast_df.index,\n",
        "                y=train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Denormalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItxmpoBbB6fB"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_forecast_df.index,\n",
        "                y=test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Denormalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor flow: predictions with Kfold validations (1D Convolutional Neural Network (CNN))"
      ],
      "metadata": {
        "id": "3jg57MthRdAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenating the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Defining the number of folds for the K-fold cross-validation\n",
        "n_folds = 5\n",
        "\n",
        "# Initializing a KFold object with the number of folds\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
        "\n",
        "# Initializing arrays to store the results of the cross-validation\n",
        "cv_scores = []\n",
        "cv_histories = []\n",
        "\n",
        "# Looping over the folds\n",
        "for train_idx, val_idx in kfold.split(train_features):\n",
        "    # Splitting the data into training and validation sets for each fold\n",
        "    x_train, x_val = train_features[train_idx], train_features[val_idx]\n",
        "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
        "    \n",
        "    # Building the neural network model using TensorFlow\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Defining callbacks to monitor the training process\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    # Reshaping the data to include a channel dimension\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "\n",
        "    # Training the model on the training data for each fold\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "    # Evaluating the model on the validation data for each fold\n",
        "    score = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "    # Appending the results of the fold to the arrays\n",
        "    cv_scores.append(score)\n",
        "    cv_histories.append(history)\n",
        "\n",
        "# Calculating the average performance of the model across all folds\n",
        "mean_score = np.mean(cv_scores, axis=0)\n",
        "\n",
        "# Printing the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "\n",
        "# Using the trained model to make predictions on the train data\n",
        "validated_train_forecast = model.predict(train_features)\n",
        "\n",
        "print(validated_train_forecast)\n",
        "print(validated_train_forecast.shape)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenate the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "validated_test_forecast = model.predict(test_features)\n",
        "\n",
        "\n",
        "# Summary: \n",
        "# The model being used is a 1D Convolutional Neural Network (CNN) built using TensorFlow. \n",
        "# It has multiple layers, including two 1D convolutional layers, two max pooling layers, a flatten layer, two dense layers, and a dropout layer. \n",
        "# It's trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error (MSE) loss function. \n",
        "# It's also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# Performming K-fold cross-validation, where the data is split into training and validation sets for each fold, and the model is trained and evaluated on each fold. \n",
        "# Finally, the trained model is used to make predictions on the train and test data.\n",
        "\n",
        "# Decided to change the model to CNN, one most commonly used for time series forecasting to validate and compare results with the previous model.\n",
        "# It is also recommended to do K-fold cross-validation in order to have a better performace estimation, reduce overfitting and helps us identifying \n",
        "# the model stability. If the performance scores low variability across different folds, it suggests that the model may perform well on unseen data.\n",
        "\n",
        "# This model approach, as the previous one, is using the train_features wihtout the second_price_auction to find the train_forecast\n",
        "#  and the test_features wihtout the second_price_auction to find the test_forecast\n"
      ],
      "metadata": {
        "id": "hGXyhmthgpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance scores"
      ],
      "metadata": {
        "id": "fmeeFT69ZKvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate the mean and standard deviation of the target variable\n",
        "target_mean = np.mean(normalized_train_auction['price_second_auction'])\n",
        "target_std = np.std(normalized_train_auction['price_second_auction'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Target Mean: \", target_mean)\n",
        "print(\"Target Standard Deviation: \", target_std)\n",
        "\n",
        "# Print the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "# Based on the performance metrics, the model is performing relatively well. \n",
        "# The average loss value of 0.064 and mean absolute error value of 0.107 \n",
        "# It indicates that the model is making predictions that are relatively close to the true values, \n",
        "# with an average absolute difference of approximately 0.11 between the predicted and true values.\n"
      ],
      "metadata": {
        "id": "oeC8CGwfYL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results plot: Plotting validated normalized values "
      ],
      "metadata": {
        "id": "-T5lsVEqQkO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdlR8rJ9QibW"
      },
      "outputs": [],
      "source": [
        "print(validated_train_forecast)\n",
        "print(validated_test_forecast)\n",
        "\n",
        "# Creating a dataframe for the train forecast\n",
        "validated_train_forecast_df = pd.DataFrame(validated_train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "validated_test_forecast_df = pd.DataFrame(validated_test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.Timestamp('2022-02-28 23:00:00')\n",
        "end_date = pd.Timestamp('2022-09-12 23:00:00')\n",
        "\n",
        "# Calculate the number of hours between start_date and end_date\n",
        "n_hours = (end_date - start_date).total_seconds() / 3600\n",
        "\n",
        "print(\"Number of hours between start and end dates:\", n_hours)\n",
        "\n"
      ],
      "metadata": {
        "id": "0FEVgWonvfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The appropriate time horizon for an accurate forecasts depends on the specific domain and the quality of the data we are working with. In the context of electricity price forecasting, short-term forecasts (e.g., a few hours to a few days ahead) are generally more accurate than long-term forecasts (e.g., weeks or months ahead) because there are fewer uncertainties involved in the short term. We could proove it when trying to make a forecast with unseen data for the test the results for long-term (10 months) forecast were not matching the test data. Different in the first models that we had becasue we were using other variables in the same datetime index in roder to find the forecast so the model was able to learn from current data and find really close predictions for the variable we are looking for. \n",
        "\n",
        "For the given data, it seems reasonable to focus on a short-term forecast, perhaps up to 24-48 hours ahead. This time horizon would allow us to capture daily patterns and fluctuations in the data, while still maintaining a reasonable level of accuracy. Keeping in mind that forecast accuracy will generally decrease as the forecasting horizon increases, so it's essential to evaluate the performance of our forecasting model and understand its limitations for longer time horizons.\n",
        "\n",
        "In the next models we are going to focus on getting short-time accurate forecast with unseen data as would be for real life trading. And then compare which model give us better predictions in order to use the data for our strategies in a double auction. "
      ],
      "metadata": {
        "id": "5c9wNJPNhEez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor flow: Predictions with Kfold validations (XGBoost model)"
      ],
      "metadata": {
        "id": "fVJcWWZhAWta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    train_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return train_features\n",
        "\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# print(train_features)\n",
        "\n",
        "# Prepare the train data and target variable\n",
        "train_data = train_features['price_second_auction']\n",
        "\n",
        "# Number of hours we want to predict into the future\n",
        "n_hours_for_prediction = 2 * 24\n",
        "\n",
        "train_features = train_features[:-n_hours_for_prediction]\n",
        "test_features = train_features[-n_hours_for_prediction:]\n",
        "\n",
        "train_target = train_data[:-n_hours_for_prediction]\n",
        "test_target = train_data[-n_hours_for_prediction:]\n",
        "\n",
        "# Set up the K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# Define the XGBoost model\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=3, random_state=42)\n",
        "\n",
        "mse_scores = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features.iloc[train_index], train_features.iloc[test_index]\n",
        "    y_train, y_test = train_target.iloc[train_index], train_target.iloc[test_index]\n",
        "    \n",
        "    # Train the model\n",
        "    xgbr.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on the test set\n",
        "    y_pred = xgbr.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "# Calculate the mean and standard deviation of the MSE scores from cross-validation\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "print(\"Mean MSE from Cross-Validation:\", mean_mse)\n",
        "print(\"Standard Deviation of MSE from Cross-Validation:\", std_mse)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "xgbr.fit(train_features, train_target)\n",
        "\n",
        "# Predict the next 2 * 24 hours\n",
        "prediction = xgbr.predict(test_features)\n",
        "\n",
        "# Assuming train_features has a DateTimeIndex\n",
        "predict_period_dates = pd.date_range('2022-03-01', periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "\n",
        "# Create a DataFrame with the forecast dates and predictions\n",
        "forecast_df = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n",
        "\n",
        "# print(forecast_df)\n",
        "\n",
        "# Plot the predictions using Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a trace for the predictions\n",
        "fig.add_trace(go.Scatter(x=forecast_df['DateTime'], y=forecast_df['Prediction'], mode='lines', name='Predictions'))\n",
        "\n",
        "fig.update_layout(title='Future Price Predictions',\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title='Price')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Gqsk2VtxctcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7po-797VqG"
      },
      "outputs": [],
      "source": [
        "# print(forecast_df.index)\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Select data within the desired time range\n",
        "train_start_date = '2022-02-26'\n",
        "train_end_date = normalized_train_auction.index.max()\n",
        "train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "validated_start_date = '2022-02-26'\n",
        "validated_end_date = validated_train_forecast_df.index.max()\n",
        "validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "test_start_date = '2022-03-01'\n",
        "test_end_date = '2022-03-04'\n",
        "test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "forecast_mask = (forecast_df['DateTime'] >= test_start_date) & (forecast_df['DateTime'] <= test_end_date)\n",
        "forecast_df = forecast_df.loc[forecast_mask]\n",
        "\n",
        "# Create the subplots and add the traces\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=forecast_df['DateTime'], y=forecast_df['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7')))\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    train_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return train_features\n",
        "\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# Create the train data\n",
        "train_data = train_features['price_second_auction']\n",
        "\n",
        "# Hyperparameter tuning for SARIMA model\n",
        "p = d = q = range(0, 2)\n",
        "pdq = list(product(p, d, q))\n",
        "seasonal_pdq = [(x[0], x[1], x[2], 24) for x in list(product(p, d, q))]\n",
        "\n",
        "best_aic = float('inf')\n",
        "best_pdq = None\n",
        "best_seasonal_pdq = None\n",
        "warnings.filterwarnings(\"ignore\")  # specify to ignore warning messages\n",
        "\n",
        "for param in pdq:\n",
        "    for param_seasonal in seasonal_pdq:\n",
        "        try:\n",
        "            model = SARIMAX(train_data, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
        "            results = model.fit()\n",
        "            if results.aic < best_aic:\n",
        "                best_aic = results.aic\n",
        "                best_pdq = param\n",
        "                best_seasonal_pdq = param_seasonal\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(f\"Best SARIMA model parameters: {best_pdq}x{best_seasonal_pdq}, AIC: {best_aic}\")\n",
        "\n",
        "# Fit the SARIMA model with the best parameters\n",
        "sarima_model = SARIMAX(train_data, order=best_pdq, seasonal_order=best_seasonal_pdq, enforce_stationarity=False, enforce_invertibility=False)\n",
        "sarima_results = sarima_model.fit()\n",
        "\n",
        "# Predict the next 2 * 24 hours\n",
        "n_hours_for_prediction = 2 * 24\n",
        "prediction = sarima_results.get_forecast(steps=n_hours_for_prediction).predicted_mean\n",
        "\n",
        "# Assuming train_features has a DateTimeIndex\n",
        "predict_period_dates = pd.date_range(train_features.index[-1] + pd.Timedelta(hours=1), periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "print(predict_period_dates)\n",
        "\n",
        "# Create a DataFrame with the forecast dates and predictions\n",
        "forecast_df = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n",
        "\n",
        "print(forecast_df)\n",
        "\n",
        "# Plot the predictions using Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a trace for the predictions\n",
        "fig.add_trace(go.Scatter(x=forecast_df['DateTime'], y=forecast_df['Prediction'], mode='lines', name='Predictions'))\n",
        "\n",
        "fig.update_layout(title='Future Price Predictions',\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title='Price')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "wMCS0RMTkmLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaQZV7kXky9p"
      },
      "outputs": [],
      "source": [
        "# print(forecast_df.index)\n",
        "\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Select data within the desired time range\n",
        "train_start_date = '2022-02-26'\n",
        "train_end_date = normalized_train_auction.index.max()\n",
        "train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "validated_start_date = '2022-02-26'\n",
        "validated_end_date = validated_train_forecast_df.index.max()\n",
        "validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "test_start_date = '2022-03-01'\n",
        "test_end_date = '2022-03-04'\n",
        "test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "forecast_mask = (forecast_df['DateTime'] >= test_start_date) & (forecast_df['DateTime'] <= test_end_date)\n",
        "forecast_df = forecast_df.loc[forecast_mask]\n",
        "\n",
        "# Create the subplots and add the traces\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=forecast_df['DateTime'], y=forecast_df['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7')))\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRADING ALGORITHM"
      ],
      "metadata": {
        "id": "Chl_6A9XaTk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "def price_first_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Calculates the winning price and traded volume for each hour in a sealed bid auction.\n",
        "    In a sealed bid auction, all bids are submitted simultaneously and the highest bid wins.\n",
        "\n",
        "    Parameters:\n",
        "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
        "    \"\"\"\n",
        "    winning_prices = []\n",
        "    traded_volumes = []\n",
        "    for hourly_bids in bids:\n",
        "        if hourly_bids:\n",
        "            winning_price = max(bid[1] for bid in hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] == winning_price)\n",
        "            traded_volumes.append(traded_volume)\n",
        "        else:\n",
        "            winning_prices.append(0)\n",
        "            traded_volumes.append(0)\n",
        "    return (winning_prices, traded_volumes)\n",
        "\n",
        "def price_second_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Calculates the winning price and traded volume for each hour in a pay-as-bid auction.\n",
        "    In a pay-as-bid auction, bids are submitted one by one, and the current winning price is set to the highest bid so far.\n",
        "\n",
        "    Parameters:\n",
        "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
        "\n",
        "    Returns:\n",
        "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
        "    \"\"\"\n",
        "    winning_prices = []\n",
        "    traded_volumes = []\n",
        "    for hourly_bids in bids:\n",
        "        if hourly_bids:\n",
        "            winning_price = max(bid[1] for bid in hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] >= winning_price)\n",
        "            traded_volumes.append(traded_volume)\n",
        "        else:\n",
        "            winning_prices.append(0)\n",
        "            traded_volumes.append(0)\n",
        "    return (winning_prices, traded_volumes)\n",
        "\n",
        "\n",
        "bids = [[(10, 20), (20, 30), (30, 25), (25, 20)]]\n",
        "\n",
        "winning_prices_first_auction = price_first_auction(bids)[0]\n",
        "traded_volumes_first_auction = price_first_auction(bids)[1]\n",
        "print(f\"Winning prices first auction : {winning_prices_first_auction}\")\n",
        "print(f\"Traded volumes first auction{traded_volumes_first_auction}\")\n",
        "\n",
        "winning_prices_second_auction = price_second_auction(bids)[0]\n",
        "traded_volumes_second_auction = price_second_auction(bids)[1]\n",
        "print(f\"Winning prices second auction : {winning_prices_second_auction}\")\n",
        "print(f\"Traded volumes second auction{traded_volumes_second_auction}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "W84WOK1ramEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}