{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andresfelipecs/suena_application_test/blob/master/algotrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQYi-jfzHR2"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rohYMPE2zHR6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "import statsmodels.api as sm\n",
        "import tensorflow as tf\n",
        "import time\n",
        "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from itertools import product\n",
        "import warnings\n",
        "from scipy.stats.distributions import norm\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from hyperopt import fmin, tpe, hp\n",
        "from functools import partial\n",
        "from typing import List, Tuple\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0JcOxFuzHR7"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzJdh92pzHR8"
      },
      "outputs": [],
      "source": [
        "# Loading the data into a Pandas DataFrame\n",
        "df_auction = pd.read_csv(\"/content/sample_data/auction_data.csv\", sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_auction['Date (WET)'] = pd.to_datetime(df_auction['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "# df_auction['date'] = df_auction['Date (WET)']\n",
        "df_auction.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "\n",
        "# Droping the first row\n",
        "units_auction = df_auction.iloc[0]\n",
        "print(units_auction)\n",
        "\n",
        "df_auction = df_auction.drop(df_auction.index[0])\n",
        "\n",
        "\n",
        "# Showing the data \n",
        "print(df_auction)\n",
        "# print(f'INDEX:  {df_auction.index} \\n')\n",
        "# print(f'TYPE:  {df_auction.dtypes} \\n')\n",
        "# print(f'SHAPE:  {df_auction.shape} \\n')\n",
        "print(f\"COLUMNS: {df_auction.columns} \\n\")\n",
        "\n",
        "# print(f'ROW {df_auction.loc[\"2021-01-01 00:00:00\" ]}')\n",
        "\n",
        "\n",
        "# Converting all the elements in the df_auction dataframe to numerical values, so that the data can be used for numerical computations and visualizations.\n",
        "df_auction = df_auction.apply(pd.to_numeric, errors='coerce')\n",
        "# The errors='coerce' argument is used to handle any elements that can't be converted to numerical values. \n",
        "# When errors='coerce', any non-numerical values will be replaced with NaN (Not a Number) values.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_auction.index,\n",
        "        y=df_auction[\"price_first_auction\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Price first auction\"\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_auction.index,\n",
        "        y=df_auction[\"price_second_auction\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Price second auction\"\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"price first auction\", \"Price second auction\", \"Traded volume first_auction\",\n",
        "                    \"Traded volume second auction\", \"Price forecast first auction\"],\n",
        "            font=dict(size=10),\n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[df_auction[k].tolist() for k in df_auction.columns[:]],\n",
        "            align = \"left\")\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    showlegend=True,\n",
        "    title_text=\"df_auction\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FEO7nvLU4NBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46vJPy1MzHSA"
      },
      "outputs": [],
      "source": [
        "df_forecast_inputs = pd.read_csv(\n",
        "            \"/content/sample_data/forecast_inputs.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_forecast_inputs['Date (WET)'] = pd.to_datetime(df_forecast_inputs['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_forecast_inputs.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_forecast_inputs = df_forecast_inputs.iloc[0]\n",
        "print(units_forecast_inputs)\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.drop(df_forecast_inputs.index[0])\n",
        "\n",
        "df_forecast_inputs = df_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_forecast_inputs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"table\"}],\n",
        "           [{\"type\": \"table\"}]]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"Demand plus system margin (MW)\", \"Demand (MW)\", \"Within day availability (MW)\",\n",
        "                    \"Margin (MW)\", \"within_day_margin (MW)\", \"Long term wind (GBP/MWh)\"],\n",
        "            font=dict(size=10),\n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[:6]],\n",
        "            align = \"left\")\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "                  \n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"Long term solar (MW)\", \"Long term wind over demand (%)\", \"long term wind over margin (%)\",\n",
        "                    \"long term solar over demand (%)\", \"long term solar over margin (%)\", \"margin over demand (%)\"],\n",
        "            font=dict(size=10),\n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[6:12]],\n",
        "            align = \"left\")\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"Snsp forecast (%)\", \"Stack price (GBP/MWh)\", \"Within day potential stack price (GBP/MWh)\",\n",
        "                    \"previous day ahead price (GBP/MWh)\", \"previous continuous half hour vwap (GBP/MWh)\", \"inertia forecast (GVA.s)\"],\n",
        "            font=dict(size=10),\n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[df_forecast_inputs[k].tolist() for k in df_forecast_inputs.columns[12:]],\n",
        "            align = \"left\")\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    showlegend=False,\n",
        "    title_text=\"df_forecast_inputs\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4YfOZL426KaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuI7_fbKzHSB"
      },
      "outputs": [],
      "source": [
        "df_system_prices = pd.read_csv(\n",
        "            \"/content/sample_data/system_prices.csv\"\n",
        "        , sep=';', header=0)\n",
        "\n",
        "# Setting the first column as an index \n",
        "df_system_prices['Date (WET)'] = pd.to_datetime(df_system_prices['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
        "df_system_prices.set_index('Date (WET)', inplace=True)\n",
        "\n",
        "# Dropping the first row\n",
        "units_system_prices = df_system_prices.iloc[0]\n",
        "print(units_system_prices)\n",
        "\n",
        "df_system_prices = df_system_prices.drop(df_system_prices.index[0])\n",
        "\n",
        "df_system_prices = df_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "print(df_system_prices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = make_subplots(\n",
        "    rows=4, cols=1,\n",
        "    shared_xaxes=True,\n",
        "    vertical_spacing=0.03,\n",
        "    specs=[[{\"type\": \"table\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}],\n",
        "           [{\"type\": \"scatter\"}]\n",
        "           ]\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"forecast_system_price_high\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Forecast system price high\"\n",
        "    ),\n",
        "    row=4, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"forecast_system_price_low\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"Forecast system price low\"\n",
        "    ),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(\n",
        "        x=df_system_prices.index,\n",
        "        y=df_system_prices[\"system_price\"],\n",
        "        mode=\"lines\",\n",
        "        name=\"System price \"\n",
        "    ),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Table(\n",
        "        header=dict(\n",
        "            values=[\"Forecast system price low GBP/MWh\", \"Forecast system price high GBP/MWh\", \"System price GBP/MWh\"],\n",
        "            font=dict(size=10),\n",
        "            align=\"left\"\n",
        "        ),\n",
        "        cells=dict(\n",
        "            values=[df_system_prices[k].tolist() for k in df_system_prices.columns[:]],\n",
        "            align = \"left\")\n",
        "    ),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    height=800,\n",
        "    showlegend=True,\n",
        "    title_text=\"df_system_prices\",\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gRcjZ1s65tx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ayrPST4ZT5q"
      },
      "source": [
        "# Cleaning and Splitting the data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq9T-fJkZXsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filling NaN with mode \n",
        "df_auction.fillna(df_auction.mode().iloc[0], inplace=True)\n",
        "df_forecast_inputs.fillna(df_forecast_inputs.mode().iloc[0], inplace=True)\n",
        "df_system_prices.fillna(df_system_prices.mode().iloc[0], inplace=True)\n",
        "\n",
        "train_auction = df_auction[df_auction.index < '2022-03-01']\n",
        "train_auction = train_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_auction = df_auction[df_auction.index >= '2022-03-01']\n",
        "test_auction = test_auction.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index < '2022-03-01']\n",
        "train_forecast_inputs = train_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index >= '2022-03-01']\n",
        "test_forecast_inputs = test_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "train_system_prices = df_system_prices[df_system_prices.index < '2022-03-01']\n",
        "train_system_prices = train_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "test_system_prices = df_system_prices[df_system_prices.index >= '2022-03-01']\n",
        "test_system_prices = test_system_prices.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Using scaler to normalize ALL the data \n",
        "scaler = StandardScaler()\n",
        "\n",
        "all_data = pd.concat([df_auction, df_forecast_inputs, df_system_prices], axis=1)\n",
        "all_data = all_data.apply(pd.to_numeric, errors='coerce')\n",
        "regression_all_data = all_data\n",
        "all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns, index=all_data.index)\n",
        "\n",
        "\n",
        "normalized_train_data = all_data[all_data.index < '2022-03-01']\n",
        "normalized_test_data = all_data[all_data.index >= '2022-03-01']\n",
        "\n",
        "normalized_train_auction = normalized_train_data[df_auction.columns]\n",
        "normalized_test_auction = normalized_test_data[df_auction.columns]\n",
        "\n",
        "normalized_train_forecast_inputs = normalized_train_data[df_forecast_inputs.columns]\n",
        "normalized_test_forecast_inputs = normalized_test_data[df_forecast_inputs.columns]\n",
        "\n",
        "normalized_train_system_prices = normalized_train_data[df_system_prices.columns]\n",
        "normalized_test_system_prices = normalized_test_data[df_system_prices.columns]\n",
        "\n",
        "print(normalized_train_auction)\n",
        "\n",
        "# Making sure there are not NaN or inf values \n",
        "print(f\"train auction null data {train_auction.isnull().sum().sum()}\")\n",
        "print(f\"train auction inf data {np.isinf(train_auction).sum().sum()}\")\n",
        "\n",
        "print(f\"train forecast input null data {train_forecast_inputs.isnull().sum().sum()}\")\n",
        "print(f\"tran forecast input inf data {np.isinf(train_forecast_inputs).sum().sum()}\")\n",
        "\n",
        "\n",
        "print(f\"train system price null data {train_system_prices.isnull().sum().sum()}\")\n",
        "print(f\"traion system price inf data {np.isinf(train_system_prices).sum().sum()}\")\n",
        "\n",
        "print(train_auction.columns)\n",
        "print(train_forecast_inputs.columns)\n",
        "print(train_system_prices.columns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression analysis using scikit-learn"
      ],
      "metadata": {
        "id": "wGOmF4_gAOXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Assuming your DataFrame is named 'regression_all_data'\n",
        "df = regression_all_data\n",
        "\n",
        "# Prepare your independent (X) and dependent (y) variables\n",
        "X = df.drop(['price_first_auction', 'price_second_auction'], axis=1)\n",
        "y = df['price_first_auction']  # Change to 'price_second_auction' if needed\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "regression_model = LinearRegression()\n",
        "regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = regression_model.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the model using metrics like Mean Squared Error (MSE) and R-squared (R²)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Check the coefficients and intercept of the model\n",
        "print(\"Coefficients:\", regression_model.coef_)\n",
        "print(\"Intercept:\", regression_model.intercept_)\n"
      ],
      "metadata": {
        "id": "zGDa6R8OAnBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression Results\n",
        "\n",
        "We performed a linear regression analysis to predict the `price_first_auction` using the given independent variables. Below are the key findings from our analysis:\n",
        "\n",
        "**Model Performance**\n",
        "\n",
        "* **Mean Squared Error (MSE):** 2917.22\n",
        "* **R-squared (R²):** 0.7875\n",
        "\n",
        "Our model achieved an R-squared value of 0.7875, which means that it explains approximately 78.75% of the variability in the `price_first_auction`. However, it's important to compare this performance to other models or a baseline model to better understand its relative performance.\n",
        "\n",
        "**Model Coefficients**\n",
        "\n",
        "The coefficients of our linear regression model provide insights into the relationships between the independent variables and the dependent variable (`price_first_auction`). The table below summarizes the coefficients:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0lSnoGd7EBha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the coefficients\n",
        "coefficients_df = pd.DataFrame({\n",
        "    'Independent Variable': [\n",
        "        'traded_volume_first_auction',\n",
        "        'traded_volume_second_auction',\n",
        "        'price_forecast_first_auction',\n",
        "        'demand_plus_system_margin',\n",
        "        'demand',\n",
        "        'within_day_availability',\n",
        "        'margin',\n",
        "        'within_day_margin',\n",
        "        'long_term_wind',\n",
        "        'long_term_solar',\n",
        "        'long_term_wind_over_demand',\n",
        "        'long_term_wind_over_margin',\n",
        "        'long_term_solar_over_demand',\n",
        "        'long_term_solar_over_margin',\n",
        "        'margin_over_demand',\n",
        "        'snsp_forecast',\n",
        "        'stack_price',\n",
        "        'within_day_potential_stack_price',\n",
        "        'previous_day_ahead_price',\n",
        "        'previous_continuous_half_hour_vwap',\n",
        "        'inertia_forecast',\n",
        "        'forecast_system_price_low',\n",
        "        'forecast_system_price_high',\n",
        "        'system_price'\n",
        "    ],\n",
        "    'Coefficient': regression_model.coef_\n",
        "})\n",
        "\n",
        "# Display the coefficients DataFrame\n",
        "pd.set_option('display.float_format', '{:.4e}'.format)  # Displayed coefficients in scientific notation\n",
        "display(coefficients_df)"
      ],
      "metadata": {
        "id": "_T5h-BHcE6JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A positive coefficient indicates that the `price_first_auction` increases as the independent variable increases, while a negative coefficient suggests the opposite. For example, the coefficient of `traded_volume_first_auction` is -0.0014, which means that as it increases by one unit, the `price_first_auction` decreases by about 0.0014 units, holding all other variables constant.\n",
        "\n",
        "**Model Intercept**\n",
        "\n",
        "The intercept of our model is 14.3816. This value represents the expected `price_first_auction` when all independent variables are equal to zero.\n",
        "\n",
        "---\n",
        "\n",
        "In conclusion, our linear regression model provides a reasonable understanding of the relationships between the independent variables and the `price_first_auction`. However, it's crucial to validate the assumptions of linear regression, perform additional diagnostics, and compare the model's performance to other models or a baseline model before drawing final conclusions.\n"
      ],
      "metadata": {
        "id": "JIYn0jYiE4a_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_plot = [\n",
        "    'price_first_auction',\n",
        "    'price_second_auction',\n",
        "    'traded_volume_first_auction',\n",
        "    'traded_volume_second_auction',\n",
        "    'price_forecast_first_auction',\n",
        "    'demand_plus_system_margin',\n",
        "    'demand',\n",
        "    'within_day_availability',\n",
        "    'margin',\n",
        "    'within_day_margin',\n",
        "    'long_term_wind',\n",
        "    'long_term_solar',\n",
        "    'long_term_wind_over_demand',\n",
        "    'long_term_wind_over_margin',\n",
        "    'long_term_solar_over_demand',\n",
        "    'long_term_solar_over_margin',\n",
        "    'margin_over_demand',\n",
        "    'snsp_forecast',\n",
        "    'stack_price',\n",
        "    'within_day_potential_stack_price',\n",
        "    'previous_day_ahead_price',\n",
        "    'previous_continuous_half_hour_vwap',\n",
        "    'inertia_forecast',\n",
        "    'forecast_system_price_low',\n",
        "    'forecast_system_price_high',\n",
        "    'system_price'\n",
        "]\n",
        "\n",
        "# Creating the scatter plot matrix\n",
        "fig = px.scatter_matrix(regression_all_data[columns_to_plot])\n",
        "\n",
        "fig.update_traces(marker=dict(size=3, opacity=0.5))\n",
        "fig.update_layout(width=1500, height=1500, title='Scatter Plot Matrix of Variables')\n",
        "\n",
        "fig.update_xaxes(tickfont=dict(size=1))\n",
        "fig.update_yaxes(tickfont=dict(size=1))\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bhmfLDumG8mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare your independent (X) and dependent (y) variables\n",
        "X = regression_all_data.drop(['price_first_auction', 'price_second_auction'], axis=1)\n",
        "y = regression_all_data['price_first_auction']  # Change to 'price_second_auction' if needed\n",
        "\n",
        "# Create a subplot for each independent variable\n",
        "fig = sp.make_subplots(rows=len(X.columns), cols=1, subplot_titles=X.columns)\n",
        "\n",
        "# Iterate through each independent variable, create a scatter plot, and add the regression line\n",
        "for i, column in enumerate(X.columns):\n",
        "    X_single = X[[column]]\n",
        "    \n",
        "    model = LinearRegression()\n",
        "    model.fit(X_single, y)\n",
        "    \n",
        "    x_range = np.linspace(X[column].min(), X[column].max(), 100).reshape(-1, 1)\n",
        "    y_range = model.predict(x_range)\n",
        "    \n",
        "    scatter = go.Scatter(x=X[column], y=y, mode='markers', name=column, marker=dict(size=3, opacity=0.65))\n",
        "    reg_line = go.Scatter(x=x_range.ravel(), y=y_range, name=f\"Regression Fit - {column}\", line=dict(color='red'))\n",
        "\n",
        "    fig.add_trace(scatter, row=i+1, col=1)\n",
        "    fig.add_trace(reg_line, row=i+1, col=1)\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(height=300*len(X.columns), width=1000, title='Scatter Plots with Regression Lines for Independent Variables')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OB6h9cttKPLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvrzoRKkZcnq"
      },
      "source": [
        "# Checking the shapes of the resulting training and testing sets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcLQL6NiZfsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"train_auction shape: \", train_auction.shape)\n",
        "print(\"test_auction shape: \", test_auction.shape)\n",
        "\n",
        "print(\"train_forecast_inputs shape: \", train_forecast_inputs.shape)\n",
        "print(\"test_forecast_inputs shape: \", test_forecast_inputs.shape)\n",
        "\n",
        "print(\"train_system_prices shape: \", train_system_prices.shape)\n",
        "print(\"test_system_prices shape: \", test_system_prices.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor flow & keras: predictions with Kfold validations (1D Convolutional Neural Network (CNN))"
      ],
      "metadata": {
        "id": "3jg57MthRdAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting the input data into features and target\n",
        "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
        "train_target = normalized_train_auction['price_second_auction']\n",
        "# Concatenating the other datasets with the training features\n",
        "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
        "\n",
        "# Defining the number of folds for the K-fold cross-validation\n",
        "n_folds = 5\n",
        "\n",
        "# Initializing a KFold object with the number of folds\n",
        "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
        "\n",
        "# Initializing arrays to store the results of the cross-validation\n",
        "cv_scores = []\n",
        "cv_histories = []\n",
        "\n",
        "# Looping over the folds\n",
        "for train_idx, val_idx in kfold.split(train_features):\n",
        "    # Splitting the data into training and validation sets for each fold\n",
        "    x_train, x_val = train_features[train_idx], train_features[val_idx]\n",
        "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
        "    \n",
        "    # Building the neural network model using TensorFlow\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "    # Defining callbacks to monitor the training process\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
        "    ]\n",
        "\n",
        "    # Reshaping the data to include a channel dimension\n",
        "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
        "    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
        "\n",
        "    # Training the model on the training data for each fold\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
        "\n",
        "    # Evaluating the model on the validation data for each fold\n",
        "    score = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "    # Appending the results of the fold to the arrays\n",
        "    cv_scores.append(score)\n",
        "    cv_histories.append(history)\n",
        "\n",
        "# Calculating the average performance of the model across all folds\n",
        "mean_score = np.mean(cv_scores, axis=0)\n",
        "\n",
        "# Printing the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "\n",
        "# Using the trained model to make predictions on the train data\n",
        "validated_train_forecast = model.predict(train_features)\n",
        "\n",
        "print(validated_train_forecast)\n",
        "print(validated_train_forecast.shape)\n",
        "\n",
        "# Use the trained model to make predictions on the test data\n",
        "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
        "\n",
        "# Concatenate the other datasets with the test features\n",
        "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
        "\n",
        "validated_test_forecast = model.predict(test_features)\n",
        "\n",
        "\n",
        "# Summary: \n",
        "# The model being used is a 1D Convolutional Neural Network (CNN) built using TensorFlow. \n",
        "# It has multiple layers, including two 1D convolutional layers, two max pooling layers, a flatten layer, two dense layers, and a dropout layer. \n",
        "# It's trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error (MSE) loss function. \n",
        "# It's also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
        "# Performming K-fold cross-validation, where the data is split into training and validation sets for each fold, and the model is trained and evaluated on each fold. \n",
        "# Finally, the trained model is used to make predictions on the train and test data.\n",
        "\n",
        "# Decided to change the model to CNN, one most commonly used for time series forecasting to validate and compare results with the previous model.\n",
        "# It is also recommended to do K-fold cross-validation in order to have a better performace estimation, reduce overfitting and helps us identifying \n",
        "# the model stability. If the performance scores low variability across different folds, it suggests that the model may perform well on unseen data.\n",
        "\n",
        "# This model approach, as the previous one, is using the train_features wihtout the second_price_auction to find the train_forecast\n",
        "#  and the test_features wihtout the second_price_auction to find the test_forecast\n"
      ],
      "metadata": {
        "id": "hGXyhmthgpd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance scores"
      ],
      "metadata": {
        "id": "fmeeFT69ZKvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean and standard deviation of the target variable\n",
        "target_mean = np.mean(normalized_train_auction['price_second_auction'])\n",
        "target_std = np.std(normalized_train_auction['price_second_auction'])\n",
        "\n",
        "# Print the results\n",
        "print(\"Target Mean: \", target_mean)\n",
        "print(\"Target Standard Deviation: \", target_std)\n",
        "\n",
        "# Print the average performance of the model\n",
        "print(\"Average performance on validation data:\")\n",
        "print(\"Loss: \", mean_score[0])\n",
        "print(\"Mean Absolute Error: \", mean_score[1])\n",
        "\n",
        "# Based on the performance metrics, the model is performing relatively well. \n",
        "# The average loss value of 0.064 and mean absolute error value of 0.107 \n",
        "# It indicates that the model is making predictions that are relatively close to the true values, \n",
        "# with an average absolute difference of approximately 0.11 between the predicted and true values.\n"
      ],
      "metadata": {
        "id": "oeC8CGwfYL6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results plot: Plotting validated normalized values "
      ],
      "metadata": {
        "id": "-T5lsVEqQkO-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdlR8rJ9QibW"
      },
      "outputs": [],
      "source": [
        "print(validated_train_forecast)\n",
        "print(validated_test_forecast)\n",
        "\n",
        "# Creating a dataframe for the train forecast\n",
        "validated_train_forecast_df = pd.DataFrame(validated_train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "# Creating a dataframe for the test forecast\n",
        "validated_test_forecast_df = pd.DataFrame(validated_test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
        "\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvFUTJ2i7hB2"
      },
      "source": [
        "## Plotting train **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIQSXK5j3THY"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_train_auction.index,\n",
        "                y=normalized_train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_train_forecast_df.index,\n",
        "                y=validated_train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Normalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILWIQbp07om-"
      },
      "source": [
        "## Plotting normalized test **prices** and **volume** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ehbc7nlp7vdW"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=normalized_test_auction.index,\n",
        "                y=normalized_test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_test_forecast_df.index,\n",
        "                y=validated_test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Normalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbDHL_W8kaXX"
      },
      "source": [
        "##  Denormalized Plots: (Results) (train **prices** and **volume**) (test **prices** and **volume**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm0jaSi9ZgDb"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Denormalizing the train forecast\n",
        "validated_train_forecast_df['price_second_auction_forecast'] = validated_train_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "# Denormalizing the test forecast\n",
        "validated_test_forecast_df['price_second_auction_forecast'] = validated_test_forecast_df['price_second_auction_forecast'] * std + mean\n",
        "\n",
        "print(f\"train forecast df : {validated_train_forecast_df['price_second_auction_forecast']}\")\n",
        "print(f\"test forecast df {validated_test_forecast_df['price_second_auction_forecast']}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYYqIgNorFOD"
      },
      "outputs": [],
      "source": [
        "# print(train_auction)\n",
        "# print(test_auction)\n",
        "\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_auction.index, y=train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.5)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_auction.index, y=test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.5)))\n",
        "\n",
        "fig.update_layout(title='Denormalized Train and Test Forecasts Second Auction ')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeqI9bwaBIE6"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=train_auction.index, y=train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_first_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"traded_volume_second_auction\"],\n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=train_auction.index,\n",
        "                y=train_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_train_forecast_df.index,\n",
        "                y=validated_train_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "            \n",
        "fig.update_layout(title='Denormalized Training Actions Prices and Volumes')\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItxmpoBbB6fB"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = make_subplots(\n",
        "            rows=2,\n",
        "            cols=2,\n",
        "            shared_xaxes=True,\n",
        "            vertical_spacing=0.08,\n",
        "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
        "            row_width=[0.2, 0.7],\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "fig.add_trace(\n",
        "            go.Scatter(x=test_auction.index, y=test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_first_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"traded_volume_second_auction\"],\n",
        "                \n",
        "                showlegend=False,\n",
        "                marker=dict(\n",
        "                    opacity=1,\n",
        "                    line=dict(width=2, color=\"#ffffb3\"),\n",
        "                ),\n",
        "            ),\n",
        "            row=2,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=test_auction.index,\n",
        "                y=test_auction[\"price_forecast_first_auction\"],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast first auction\",\n",
        "                line=dict(color=\"#fdb462\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=1,\n",
        "        )\n",
        "\n",
        "fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=validated_test_forecast_df.index,\n",
        "                y=validated_test_forecast_df['price_second_auction_forecast'],\n",
        "                mode=\"lines\",\n",
        "                name=\"Price train forecast second auction\",\n",
        "                line=dict(color=\"#80b1d3\", width=0.5),\n",
        "            ),\n",
        "            row=1,\n",
        "            col=2,\n",
        "        )\n",
        "\n",
        "fig.update_layout(title='Denormalized Test Actions Prices and Volumes', showlegend=True)\n",
        "fig.update_yaxes(title='Price', row=1)\n",
        "fig.update_xaxes(title='Date', row=2)\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_date = pd.Timestamp('2022-02-28 23:00:00')\n",
        "end_date = pd.Timestamp('2022-09-12 23:00:00')\n",
        "\n",
        "# Calculate the number of hours between start_date and end_date\n",
        "n_hours = (end_date - start_date).total_seconds() / 3600\n",
        "\n",
        "print(\"Number of hours between start and end dates:\", n_hours)\n",
        "\n"
      ],
      "metadata": {
        "id": "0FEVgWonvfvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNSEEN DATA SHORT TERM PREDICTIONS** "
      ],
      "metadata": {
        "id": "DmImoeBHalsU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The optimal time frame for precise forecasting is contingent upon the specific field and the quality of the data at hand. Within the realm of electricity price forecasting, short-term predictions (e.g., spanning a few hours to several days) tend to exhibit greater accuracy compared to their long-term counterparts (e.g., those extending over weeks or months). This is primarily due to the reduced uncertainty associated with shorter time frames. As evidenced by our attempt to forecast using previously unseen data, long-term projections (spanning 10 months) failed to align with the test data. In contrast, our initial models exhibited greater accuracy as they incorporated additional variables within the same time index, enabling the model to learn from contemporaneous data and generate more accurate predictions for the target variable.\n",
        "\n",
        "Given the nature of the data, it appears prudent to concentrate on short-term forecasting, potentially within a 24-48 hour window. This time frame would enable the capture of daily trends and variations while maintaining a satisfactory level of precision. It is crucial to bear in mind that forecast accuracy typically declines as the prediction horizon expands. As such, it is essential to assess the performance of our forecasting model and recognize its limitations over extended periods.\n",
        "\n",
        "Moving forward, our subsequent models will prioritize generating accurate short-term forecasts using previously unseen data, as would be the case in real-world trading scenarios. Subsequently, we will compare the predictive capabilities of various models to determine the most suitable approach for incorporating this data into our double auction strategies."
      ],
      "metadata": {
        "id": "5c9wNJPNhEez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost model: Predictions with Kfold validations "
      ],
      "metadata": {
        "id": "fVJcWWZhAWta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "    train_features = pd.concat([normalized_train_auction,\n",
        "                                  normalized_train_forecast_inputs,\n",
        "                                  normalized_train_system_prices], axis=1)\n",
        "    return train_features\n",
        "\n",
        "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "\n",
        "# print(train_features)\n",
        "\n",
        "# Prepare the train data and target variable\n",
        "train_data = train_features['price_second_auction']\n",
        "\n",
        "# Number of hours we want to predict into the future\n",
        "n_hours_for_prediction = 2 * 24\n",
        "\n",
        "train_features = train_features[:-n_hours_for_prediction]\n",
        "test_features = train_features[-n_hours_for_prediction:]\n",
        "\n",
        "train_target = train_data[:-n_hours_for_prediction]\n",
        "test_target = train_data[-n_hours_for_prediction:]\n",
        "\n",
        "# Set up the K-Fold cross-validation\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "# Define the XGBoost model\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=3, random_state=42)\n",
        "\n",
        "mse_scores = []\n",
        "\n",
        "# Perform cross-validation\n",
        "for train_index, test_index in kf.split(train_features):\n",
        "    X_train, X_test = train_features.iloc[train_index], train_features.iloc[test_index]\n",
        "    y_train, y_test = train_target.iloc[train_index], train_target.iloc[test_index]\n",
        "    \n",
        "    # Train the model\n",
        "    xgbr.fit(X_train, y_train)\n",
        "    \n",
        "    # Make predictions on the test set\n",
        "    y_pred = xgbr.predict(X_test)\n",
        "    \n",
        "    # Calculate the mean squared error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_scores.append(mse)\n",
        "\n",
        "# Calculate the mean and standard deviation of the MSE scores from cross-validation\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "print(\"Mean MSE from Cross-Validation:\", mean_mse)\n",
        "print(\"Standard Deviation of MSE from Cross-Validation:\", std_mse)\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "xgbr.fit(train_features, train_target)\n",
        "\n",
        "# Predict the next 2 * 24 hours\n",
        "prediction = xgbr.predict(test_features)\n",
        "\n",
        "# Assuming train_features has a DateTimeIndex\n",
        "predict_period_dates = pd.date_range('2022-03-01', periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "\n",
        "# Create a DataFrame with the forecast dates and predictions\n",
        "future_forecast_df = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n",
        "\n",
        "# print(future_forecast_df)\n",
        "\n",
        "# Plot the predictions using Plotly\n",
        "fig = go.Figure()\n",
        "\n",
        "# Add a trace for the predictions\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df['DateTime'], y=future_forecast_df['Prediction'], mode='lines', name='Predictions'))\n",
        "\n",
        "fig.update_layout(title='Future Price Predictions',\n",
        "                  xaxis_title='Date',\n",
        "                  yaxis_title='Price')\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Gqsk2VtxctcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results plot: Normalized trin and comparison between forecast df made by XGBoost model with unseen data and the given test data "
      ],
      "metadata": {
        "id": "MugL81aCHYD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Normalizing the train forecast\n",
        "validated_train_forecast_df['price_second_auction_forecast'] = (validated_train_forecast_df['price_second_auction_forecast'] - mean) / std\n",
        "\n",
        "# Normalizing the test forecast\n",
        "validated_test_forecast_df['price_second_auction_forecast'] = (validated_test_forecast_df['price_second_auction_forecast'] - mean) / std\n"
      ],
      "metadata": {
        "id": "cF3KeAErCBSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7po-797VqG"
      },
      "outputs": [],
      "source": [
        "print(future_forecast_df.index)\n",
        "\n",
        "# Select data within the desired time range\n",
        "train_start_date = '2022-02-26'\n",
        "train_end_date = normalized_train_auction.index.max()\n",
        "train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "validated_start_date = '2022-02-26'\n",
        "validated_end_date = validated_train_forecast_df.index.max()\n",
        "validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "test_start_date = '2022-03-01'\n",
        "test_end_date = '2022-03-04'\n",
        "test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "forecast_mask = (future_forecast_df['DateTime'] >= test_start_date) & (future_forecast_df['DateTime'] <= test_end_date)\n",
        "future_forecast_df = future_forecast_df.loc[forecast_mask]\n",
        "\n",
        "# Create the subplots and add the traces\n",
        "fig = make_subplots()\n",
        "\n",
        "fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "fig.add_trace(go.Scatter(x=future_forecast_df['DateTime'], y=future_forecast_df['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7')))\n",
        "\n",
        "# Update the layout\n",
        "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "fig.update_xaxes(title='Date')\n",
        "fig.update_yaxes(title='Price')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SARIMAX\n",
        "Regrettably, the current approach demands substantial system RAM and considerable processing time, without yielding improved predictions compared to our previous model. However, utilizing a GPU with increased memory capacity, potentially through cloud-based services, could streamline this process and facilitate the development of progressively superior models for our forecasting endeavors."
      ],
      "metadata": {
        "id": "tKx5gN7M2yIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
        "#     train_features = pd.concat([normalized_train_auction,\n",
        "#                                   normalized_train_forecast_inputs,\n",
        "#                                   normalized_train_system_prices], axis=1)\n",
        "#     return train_features\n",
        "\n",
        "# train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
        "# train_data = train_features['price_second_auction']\n",
        "\n",
        "# warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# space = {\n",
        "#     'p': hp.choice('p', range(0, 2)),\n",
        "#     'd': hp.choice('d', range(0, 2)),\n",
        "#     'q': hp.choice('q', range(0, 2)),\n",
        "#     'P': hp.choice('P', range(0, 2)),\n",
        "#     'D': hp.choice('D', range(0, 2)),\n",
        "#     'Q': hp.choice('Q', range(0, 2)),\n",
        "# }\n",
        "\n",
        "# def objective(params, train_data_np):\n",
        "#     model = SARIMAX(train_data_np, order=(params['p'], params['d'], params['q']), seasonal_order=(params['P'], params['D'], params['Q'], 24), enforce_stationarity=False, enforce_invertibility=False)\n",
        "#     try:\n",
        "#         results = model.fit()\n",
        "#         return results.aic\n",
        "#     except:\n",
        "#         return float('inf')\n",
        "\n",
        "# train_data_np = train_data.to_numpy()\n",
        "\n",
        "# best = fmin(partial(objective, train_data_np=train_data_np), space, algo=tpe.suggest, max_evals=50)\n",
        "\n",
        "# best_pdq = (best['p'], best['d'], best['q'])\n",
        "# best_seasonal_pdq = (best['P'], best['D'], best['Q'], 24)\n",
        "\n",
        "# print(f\"Best SARIMA model parameters: {best_pdq}x{best_seasonal_pdq}\")\n",
        "\n",
        "# sarima_model = SARIMAX(train_data, order=best_pdq, seasonal_order=best_seasonal_pdq, enforce_stationarity=False, enforce_invertibility=False)\n",
        "# sarima_results = sarima_model.fit()\n",
        "\n",
        "# n_hours_for_prediction = 2 * 24\n",
        "# prediction = sarima_results.get_forecast(steps=n_hours_for_prediction).predicted_mean\n",
        "\n",
        "# predict_period_dates = pd.date_range(train_features.index[-1] + pd.Timedelta(hours=1), periods=n_hours_for_prediction, freq=\"H\").tolist()\n",
        "\n",
        "# future_forecast_df2 = pd.DataFrame({'DateTime': predict_period_dates, 'Prediction': prediction})\n",
        "\n",
        "# fig = go.Figure()\n",
        "# fig.add_trace(go.Scatter(x=future_forecast_df2['DateTime'], y=future_forecast_df2['Prediction'], mode='lines', name='Predictions'))\n",
        "\n",
        "# fig.update_layout(title='Future Price Predictions',\n",
        "#                   xaxis_title='Date',\n",
        "#                   yaxis_title='Price')\n",
        "\n",
        "# fig.show()\n"
      ],
      "metadata": {
        "id": "wMCS0RMTkmLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Sarimax plot: normalized train data and comparison between test data and the Sarimax forecast df made with unseen data"
      ],
      "metadata": {
        "id": "Op-I27ZKIOVT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TswCw9cYIM8x"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Select data within the desired time range\n",
        "# train_start_date = '2022-02-26'\n",
        "# train_end_date = normalized_train_auction.index.max()\n",
        "# train_mask = (normalized_train_auction.index >= train_start_date) & (normalized_train_auction.index <= train_end_date)\n",
        "# train_df = normalized_train_auction.loc[train_mask]\n",
        "\n",
        "# validated_start_date = '2022-02-26'\n",
        "# validated_end_date = validated_train_forecast_df.index.max()\n",
        "# validated_mask = (validated_train_forecast_df.index >= validated_start_date) & (validated_train_forecast_df.index <= validated_end_date)\n",
        "# validated_df = validated_train_forecast_df.loc[validated_mask]\n",
        "\n",
        "# test_start_date = '2022-03-01'\n",
        "# test_end_date = '2022-03-04'\n",
        "# test_mask = (normalized_test_auction.index >= test_start_date) & (normalized_test_auction.index <= test_end_date)\n",
        "# test_df = normalized_test_auction.loc[test_mask]\n",
        "\n",
        "# forecast_mask = (future_forecast_df2['DateTime'] >= test_start_date) & (future_forecast_df2['DateTime'] <= test_end_date)\n",
        "# future_forecast_df2 = future_forecast_df2.loc[forecast_mask]\n",
        "\n",
        "# # Create the subplots and add the traces\n",
        "# fig = make_subplots()\n",
        "\n",
        "# fig.add_trace(go.Scatter(x=train_df.index, y=train_df['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
        "# fig.add_trace(go.Scatter(x=validated_df.index, y=validated_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
        "\n",
        "# fig.add_trace(go.Scatter(x=test_df.index, y=test_df['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
        "# fig.add_trace(go.Scatter(x=future_forecast_df2['DateTime'], y=future_forecast_df2['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7')))\n",
        "\n",
        "# # Update the layout\n",
        "# fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
        "# fig.update_xaxes(title='Date')\n",
        "# fig.update_yaxes(title='Price')\n",
        "\n",
        "# # Show the plot\n",
        "# fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRADING ALGORITHM**"
      ],
      "metadata": {
        "id": "Chl_6A9XaTk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon evaluating the outcomes of various models, the XGBoost and SARIMAX models emerge as the top performers in terms of runtime, RAM usage, computational efficiency, and accuracy. Among these two contenders, the XGBoost model demonstrates superior precision, and as such, we will utilize its predictive values to inform our strategic approach."
      ],
      "metadata": {
        "id": "Q5BiYN6rQ8oL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We assume that the \"future data\" represents the test data prices for each auction, with the initial price obtained from the forecast of the first auction already provided. For the second price, we will employ the future_forecast_df dataframe, derived from the XGBoost model, under the pretense that the test data was unseen, thereby allowing for an accuracy comparison. This information will be utilized to determine the appropriate bids and volumes, which will then be integrated into our trading algorithm."
      ],
      "metadata": {
        "id": "YdxpSGpPSSbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import random\n",
        "import pandas as pd\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "A2L_Nlo8IZ2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organizing input data"
      ],
      "metadata": {
        "id": "s5hQs4_lYWy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First we need to denormalize the XGBoost model results.\n",
        "\n",
        "# Getting the mean and standard deviation used during normalization\n",
        "mean = scaler.mean_[0]\n",
        "std = scaler.scale_[0]\n",
        "\n",
        "# Denormalizing the future forecast\n",
        "future_forecast_df['Prediction'] = future_forecast_df['Prediction'] * std + mean\n",
        "print(f\"{future_forecast_df}\")\n",
        "\n",
        "test_auction = test_auction[test_auction.index < '2022-03-02 23:00:00']\n",
        "print(test_auction[\"price_forecast_first_auction\"])\n",
        "\n",
        "test_forecast_inputs = test_forecast_inputs[test_forecast_inputs.index < '2022-03-02 23:00:00']\n",
        "print(f\"test_forecast_inputs {test_forecast_inputs.columns}\")\n",
        "\n",
        "test_system_prices = test_system_prices[test_system_prices.index < '2022-03-02 23:00:00']\n",
        "print(f\"test_system_prices {test_system_prices.columns}\")\n",
        "\n",
        "test_auction = test_auction[test_auction.index < '2022-03-02 23:00:00']\n",
        "print(f\"test_auction {test_auction.columns}\")\n"
      ],
      "metadata": {
        "id": "gvxtKBxiB-mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate the bids and the volume"
      ],
      "metadata": {
        "id": "N0pYZ3xVW4t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BidStrategy:\n",
        "    def __init__(self, train_auction, train_system_prices, train_forecast_inputs, test_auction, test_system_prices, test_forecast_inputs, future_forecast_df):\n",
        "        self.train_auction = train_auction\n",
        "        self.train_system_prices = train_system_prices\n",
        "        self.train_forecast_inputs = train_forecast_inputs\n",
        "        self.test_auction = test_auction\n",
        "        self.test_system_prices = test_system_prices\n",
        "        self.test_forecast_inputs = test_forecast_inputs\n",
        "        self.future_forecast_df = future_forecast_df\n",
        "\n",
        "    def analyze_data(self):\n",
        "        # Analyze historical data to identify trends and patterns\n",
        "        # You can add logic to process the train_auction, train_system_prices, and train_forecast_inputs dataframes\n",
        "        pass\n",
        "\n",
        "    def predict_future_prices(self):\n",
        "        # Use forecasted data to predict short-term price movements\n",
        "        # You can add logic to process the test_auction and future_forecast_df dataframes\n",
        "        pass\n",
        "\n",
        "    def calculate_bids(self):\n",
        "        self.analyze_data()\n",
        "        self.predict_future_prices()\n",
        "\n",
        "        # Calculating clearing prices for each auction\n",
        "        clear_price_1 = self.test_auction['price_forecast_first_auction'].max()\n",
        "        clear_price_2 = self.future_forecast_df['Prediction'].max()\n",
        "\n",
        "        # Calculating payments for each bidder based on their bids\n",
        "        payment_1 = clear_price_1 - self.test_system_prices['system_price'].values\n",
        "        payment_2 = clear_price_2 - self.test_system_prices['system_price'].values\n",
        "\n",
        "        # Calculating revenues for each bidder based on their payments and winning quantity\n",
        "        revenue_1 = payment_1 * self.test_forecast_inputs['demand'].values\n",
        "        revenue_2 = payment_2 * self.test_forecast_inputs['demand'].values\n",
        "\n",
        "        # Calculating the traded volume for each bidder based on their revenue and clearing price\n",
        "        volume_1 = revenue_1 / clear_price_1\n",
        "        volume_2 = revenue_2 / clear_price_2\n",
        "\n",
        "        # Calculating the bid price and traded volume for each bidder\n",
        "        bid_price_1 = clear_price_1 - (revenue_1 / volume_1)\n",
        "        bid_price_2 = clear_price_2 - (revenue_2 / volume_2)\n",
        "        traded_volume_1 = self.test_auction['traded_volume_first_auction'].values\n",
        "        traded_volume_2 = self.test_auction['traded_volume_second_auction'].values\n",
        "\n",
        "        # Returning hourly bids as a list of tuples with traded volume and bid price\n",
        "        hourly_bids = [(int(traded_volume_1[i]), bid_price_1[i]) for i in range(len(bid_price_1))]\n",
        "        hourly_bids += [(int(traded_volume_2[i]), bid_price_2[i]) for i in range(len(bid_price_2))]\n",
        "        return hourly_bids\n",
        "\n",
        "# Instantiating the BidStrategy class \n",
        "bid_strategy = BidStrategy(train_auction, train_system_prices, train_forecast_inputs, test_auction, test_system_prices, test_forecast_inputs, future_forecast_df)\n",
        "\n",
        "bids = bid_strategy.calculate_bids()\n",
        "\n",
        "print(bids)\n"
      ],
      "metadata": {
        "id": "U_Vi_vc1IEMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trading tool and further analysis"
      ],
      "metadata": {
        "id": "aso1mIHhXORa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Auction:\n",
        "    def __init__(self, train_auction, future_forecast_df, threshold=0.1):\n",
        "        self.train_auction = train_auction\n",
        "        self.future_forecast_df = future_forecast_df\n",
        "        self.threshold = threshold\n",
        "        self.bids = []\n",
        "\n",
        "    def analyze_predicted_prices(self):\n",
        "        # Calculate the price differences between the two auctions\n",
        "        self.train_auction[\"price_difference\"] = self.future_forecast_df[\"Predictions\"] - self.train_auction[\"price_forecast_first_auction\"]\n",
        "        self.train_auction[\"price_difference_percentage\"] = self.train_auction[\"price_difference\"] / self.train_auction[\"price_forecast_first_auction\"]\n",
        "        \n",
        "        # Identify opportunities for arbitrage\n",
        "        self.train_auction[\"arbitrage_opportunity\"] = self.train_auction[\"price_difference_percentage\"].apply(lambda x: x > self.threshold)\n",
        "        \n",
        "        return self.train_auction\n",
        "\n",
        "    def place_bids(self):\n",
        "        analyzed_prices = self.analyze_predicted_prices()\n",
        "        for _, row in analyzed_prices.iterrows():\n",
        "            if row[\"arbitrage_opportunity\"]:\n",
        "                bid = (row[\"volume\"], row[\"price_forecast_first_auction\"])\n",
        "            else:\n",
        "                bid = (0, 0)\n",
        "            self.bids.append(bid)\n",
        "\n",
        "    def price_range_system_price(self) -> Tuple[float, float]:\n",
        "        return (-10, 10)\n",
        "\n",
        "    def calculate_system_price(self, system_price_range: Tuple[float, float]) -> float:\n",
        "        return random.uniform(system_price_range[0], system_price_range[1])\n",
        "\n",
        "    def price_auction(self, bids: List[Tuple[float, float]]) -> Tuple[float, float]:\n",
        "        if bids:\n",
        "            winning_price = max(bid[1] for bid in bids)\n",
        "            net_position = sum(bid[0] for bid in bids if bid[1] >= winning_price)\n",
        "        else:\n",
        "            winning_price = 0\n",
        "            net_position = 0\n",
        "        return (winning_price, net_position)\n",
        "\n",
        "    def calculate_profit_loss(self, net_positions: List[float], winning_prices: List[float], system_price: float) -> List[float]:\n",
        "        profit_loss = []\n",
        "        for i in range(len(net_positions)):\n",
        "            trade_cost = abs(net_positions[i]) * 5\n",
        "            net_position_value = net_positions[i] * winning_prices[i] - trade_cost\n",
        "\n",
        "            if net_positions[i] < 0:\n",
        "                net_position_value += abs(net_positions[i]) * system_price\n",
        "            elif net_positions[i] > 0:\n",
        "                net_position_value -= net_positions[i] * system_price\n",
        "\n",
        "            profit_loss.append(net_position_value)\n",
        "        return profit_loss\n",
        "\n",
        "    def submit_bids(self, bids: List[Tuple[float, float]]):\n",
        "        self.bids.append(bids)\n",
        "\n",
        "    def run_auctions(self):\n",
        "        system_price_range = self.price_range_system_price()\n",
        "        system_price = self.calculate_system_price(system_price_range)\n",
        "\n",
        "        winning_prices = []\n",
        "        net_positions = []\n",
        "\n",
        "        for hourly_bids in self.bids:\n",
        "            winning_price, net_position = self.price_auction(hourly_bids)\n",
        "            winning_prices.append(winning_price)\n",
        "            net_positions.append(net_position)\n",
        "\n",
        "        profit_loss = self.calculate_profit_loss(net_positions, winning_prices, system_price)\n",
        "        return winning_prices, net_positions, profit_loss\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W84WOK1ramEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auction = Auction()\n",
        "\n",
        "# Submit bids for each hour of the next operating day\n",
        "hourly_bids = [\n",
        "    (10, 20), (20, 30), (30, 25), (25, 20)\n",
        "]\n",
        "\n",
        "for hour in range(24):\n",
        "    auction.submit_bids(hourly_bids)\n",
        "\n",
        "# First auction results\n",
        "winning_prices1, net_positions1, _ = auction.run_auctions()\n",
        "\n",
        "# Second auction bids\n",
        "bids_second_auction = [(-bid[0], bid[1]) for bid in hourly_bids]\n",
        "\n",
        "auction = Auction()\n",
        "for hour in range(24):\n",
        "    auction.submit_bids(bids_second_auction)\n",
        "\n",
        "# Second auction results\n",
        "winning_prices2, net_positions2, _ = auction.run_auctions()\n",
        "\n",
        "# Calculate net positions and profit/loss\n",
        "net_positions = [net1 + net2 for net1, net2 in zip(net_positions1, net_positions2)]\n",
        "winning_prices = [(price1 + price2) / 2 for price1, price2 in zip(winning_prices1, winning_prices2)]\n",
        "system_price_range = auction.price_range_system_price()\n",
        "system_price = auction.calculate_system_price(system_price_range)\n",
        "profit_loss = auction.calculate_profit_loss(net_positions, winning_prices, system_price)\n",
        "\n",
        "print(f\"Winning prices: {winning_prices}\")\n",
        "print(f\"Net positions: {net_positions}\")\n",
        "print(f\"Profit/loss for both auctions: {profit_loss}\")"
      ],
      "metadata": {
        "id": "rQ_Oshj5ICk2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}