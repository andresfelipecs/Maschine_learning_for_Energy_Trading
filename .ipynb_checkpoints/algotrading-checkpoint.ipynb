{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/andresfelipecs/suena_application_test/blob/master/algotrading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GQYi-jfzHR2"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rohYMPE2zHR6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import TimeSeriesSplit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0JcOxFuzHR7"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bzJdh92pzHR8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the data into a Pandas DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_auction \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/sample_data/auction_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Setting the first column as an index \u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_auction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_auction[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading the data into a Pandas DataFrame\n",
    "df_auction = pd.read_csv(\"/content/sample_data/auction_data.csv\", sep=';', header=0)\n",
    "\n",
    "# Setting the first column as an index \n",
    "df_auction['Date (WET)'] = pd.to_datetime(df_auction['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
    "# df_auction['date'] = df_auction['Date (WET)']\n",
    "df_auction.set_index('Date (WET)', inplace=True)\n",
    "\n",
    "\n",
    "# Droping the first row\n",
    "units_auction = df_auction.iloc[0]\n",
    "print(units_auction)\n",
    "\n",
    "df_auction = df_auction.drop(df_auction.index[0])\n",
    "\n",
    "\n",
    "# Showing the data \n",
    "print(df_auction)\n",
    "# print(f'INDEX:  {df_auction.index} \\n')\n",
    "# print(f'TYPE:  {df_auction.dtypes} \\n')\n",
    "# print(f'SHAPE:  {df_auction.shape} \\n')\n",
    "print(f\"COLUMNS: {df_auction.columns} \\n\")\n",
    "\n",
    "# print(f'ROW {df_auction.loc[\"2021-01-01 00:00:00\" ]}')\n",
    "\n",
    "\n",
    "# Converting all the elements in the df_auction dataframe to numerical values, so that the data can be used for numerical computations and visualizations.\n",
    "df_auction = df_auction.apply(pd.to_numeric, errors='coerce')\n",
    "# The errors='coerce' argument is used to handle any elements that can't be converted to numerical values. \n",
    "# When errors='coerce', any non-numerical values will be replaced with NaN (Not a Number) values.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "46vJPy1MzHSA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_forecast_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m      2\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/sample_data/forecast_inputs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m         , sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Setting the first column as an index \u001b[39;00m\n\u001b[1;32m      6\u001b[0m df_forecast_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_forecast_inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_forecast_inputs = pd.read_csv(\n",
    "            \"/content/sample_data/forecast_inputs.csv\"\n",
    "        , sep=';', header=0)\n",
    "\n",
    "# Setting the first column as an index \n",
    "df_forecast_inputs['Date (WET)'] = pd.to_datetime(df_forecast_inputs['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
    "df_forecast_inputs.set_index('Date (WET)', inplace=True)\n",
    "\n",
    "# Dropping the first row\n",
    "units_forecast_inputs = df_forecast_inputs.iloc[0]\n",
    "print(units_forecast_inputs)\n",
    "\n",
    "df_forecast_inputs = df_forecast_inputs.drop(df_forecast_inputs.index[0])\n",
    "\n",
    "df_forecast_inputs = df_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "print(df_forecast_inputs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nuI7_fbKzHSB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_system_prices \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m      2\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/sample_data/system_prices.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m         , sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Setting the first column as an index \u001b[39;00m\n\u001b[1;32m      6\u001b[0m df_system_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_system_prices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate (WET)\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_system_prices = pd.read_csv(\n",
    "            \"/content/sample_data/system_prices.csv\"\n",
    "        , sep=';', header=0)\n",
    "\n",
    "# Setting the first column as an index \n",
    "df_system_prices['Date (WET)'] = pd.to_datetime(df_system_prices['Date (WET)'], format='[%d/%m/%Y %H:%M]')\n",
    "df_system_prices.set_index('Date (WET)', inplace=True)\n",
    "\n",
    "# Dropping the first row\n",
    "units_system_prices = df_system_prices.iloc[0]\n",
    "print(units_system_prices)\n",
    "\n",
    "df_system_prices = df_system_prices.drop(df_system_prices.index[0])\n",
    "\n",
    "df_system_prices = df_system_prices.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "print(df_system_prices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ayrPST4ZT5q"
   },
   "source": [
    "# Cleaning and Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bq9T-fJkZXsQ"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "# Filling NaN with mode \n",
    "df_auction.fillna(df_auction.mode().iloc[0], inplace=True)\n",
    "df_forecast_inputs.fillna(df_forecast_inputs.mode().iloc[0], inplace=True)\n",
    "df_system_prices.fillna(df_system_prices.mode().iloc[0], inplace=True)\n",
    "\n",
    "train_auction = df_auction[df_auction.index < '2022-03-01']\n",
    "train_auction = train_auction.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "test_auction = df_auction[df_auction.index >= '2022-03-01']\n",
    "test_auction = test_auction.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "train_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index < '2022-03-01']\n",
    "train_forecast_inputs = train_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "test_forecast_inputs = df_forecast_inputs[df_forecast_inputs.index >= '2022-03-01']\n",
    "test_forecast_inputs = test_forecast_inputs.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "train_system_prices = df_system_prices[df_system_prices.index < '2022-03-01']\n",
    "train_system_prices = train_system_prices.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "test_system_prices = df_system_prices[df_system_prices.index >= '2022-03-01']\n",
    "test_system_prices = test_system_prices.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Using scaler to normalize ALL the data \n",
    "scaler = StandardScaler()\n",
    "\n",
    "all_data = pd.concat([df_auction, df_forecast_inputs, df_system_prices], axis=1)\n",
    "all_data = all_data.apply(pd.to_numeric, errors='coerce')\n",
    "all_data = pd.DataFrame(scaler.fit_transform(all_data), columns=all_data.columns, index=all_data.index)\n",
    "\n",
    "\n",
    "normalized_train_data = all_data[all_data.index < '2022-03-01']\n",
    "normalized_test_data = all_data[all_data.index >= '2022-03-01']\n",
    "\n",
    "normalized_train_auction = normalized_train_data[df_auction.columns]\n",
    "normalized_test_auction = normalized_test_data[df_auction.columns]\n",
    "\n",
    "normalized_train_forecast_inputs = normalized_train_data[df_forecast_inputs.columns]\n",
    "normalized_test_forecast_inputs = normalized_test_data[df_forecast_inputs.columns]\n",
    "\n",
    "normalized_train_system_prices = normalized_train_data[df_system_prices.columns]\n",
    "normalized_test_system_prices = normalized_test_data[df_system_prices.columns]\n",
    "\n",
    "print(normalized_train_auction)\n",
    "\n",
    "# Making sure there are not NaN or inf values \n",
    "print(f\"train auction null data {train_auction.isnull().sum().sum()}\")\n",
    "print(f\"train auction inf data {np.isinf(train_auction).sum().sum()}\")\n",
    "\n",
    "print(f\"train forecast input null data {train_forecast_inputs.isnull().sum().sum()}\")\n",
    "print(f\"tran forecast input inf data {np.isinf(train_forecast_inputs).sum().sum()}\")\n",
    "\n",
    "\n",
    "print(f\"train system price null data {train_system_prices.isnull().sum().sum()}\")\n",
    "print(f\"traion system price inf data {np.isinf(train_system_prices).sum().sum()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4UGlTAuoevg"
   },
   "source": [
    "# Plotting normalized train forecats inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHWkdEjioj68"
   },
   "outputs": [],
   "source": [
    "fig = px.line(normalized_train_forecast_inputs, x=normalized_train_forecast_inputs.index, y=normalized_train_forecast_inputs.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCtrGu_dn5ST"
   },
   "outputs": [],
   "source": [
    "fig = px.line(normalized_train_system_prices, x=normalized_train_system_prices.index, y=normalized_train_system_prices.columns)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvrzoRKkZcnq"
   },
   "source": [
    "# Checking the shapes of the resulting training and testing sets\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcLQL6NiZfsQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"train_auction shape: \", train_auction.shape)\n",
    "print(\"test_auction shape: \", test_auction.shape)\n",
    "\n",
    "print(\"train_forecast_inputs shape: \", train_forecast_inputs.shape)\n",
    "print(\"test_forecast_inputs shape: \", test_forecast_inputs.shape)\n",
    "\n",
    "print(\"train_system_prices shape: \", train_system_prices.shape)\n",
    "print(\"test_system_prices shape: \", test_system_prices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpJmpPLO2pEN"
   },
   "source": [
    "# Tensor flow: **Neural network**, **model** and **forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HYK8FLu2sa6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the input data into features and target\n",
    "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
    "train_target = normalized_train_auction['price_second_auction']\n",
    "# Concatenating the other datasets with the training features\n",
    "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
    "\n",
    "# Building the neural network model using TensorFlow\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu', input_shape=(train_features.shape[1],)))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.1))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Defining callbacks to monitor the training process\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
    "]\n",
    "\n",
    "# Trainning the model on the training data\n",
    "history = model.fit(train_features, train_target, epochs=100, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "# Using the trained model to make predictions on the train data\n",
    "train_forecast = model.predict(train_features)\n",
    "\n",
    "# Using the trained model to make predictions on the test data\n",
    "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
    "\n",
    "# Concatenating the other datasets with the test features\n",
    "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
    "\n",
    "test_forecast = model.predict(test_features)\n",
    "\n",
    "print(f\"train forecast {train_forecast.shape}\")\n",
    "print(f\"test forecast {test_forecast.shape}\")\n",
    "\n",
    "# Summary: \n",
    "# The model built using TensorFlow is a sequential neural network type DNN (Deep Neural Network) model, as it consists of multiple densely connected layers of neuron. \n",
    "# The model has three dense layers with 64 neurons in each layer and uses the Rectified Linear Unit (ReLU) activation function\n",
    "# for the first two layers and a linear activation function for the last layer. \n",
    "# The model is trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error loss function. \n",
    "# The model is also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
    "# The trained model is then used to make predictions on the train and test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbiFs2y3v0Lh"
   },
   "source": [
    "# Performance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87qsO0t_YjTc"
   },
   "source": [
    "# Results plot:  **train second auction**, **test second auction**, **train forecast**, **test forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mnbjZdJvuxoA"
   },
   "outputs": [],
   "source": [
    "# print(train_forecast)\n",
    "# print(test_forecast)\n",
    "# Creating a dataframe for the train forecast\n",
    "train_forecast_df = pd.DataFrame(train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
    "\n",
    "# Creating a dataframe for the test forecast\n",
    "test_forecast_df = pd.DataFrame(test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
    "\n",
    "fig = make_subplots()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
    "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
    "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
    "\n",
    "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Price')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvFUTJ2i7hB2"
   },
   "source": [
    "# Plotting train **prices** and **volume** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIQSXK5j3THY"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = make_subplots(\n",
    "            rows=2,\n",
    "            cols=2,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.08,\n",
    "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
    "            row_width=[0.2, 0.7],\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=normalized_train_auction.index,\n",
    "                y=normalized_train_auction[\"traded_volume_first_auction\"],\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=normalized_train_auction.index,\n",
    "                y=normalized_train_auction[\"traded_volume_second_auction\"],\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=normalized_train_auction.index,\n",
    "                y=normalized_train_auction[\"price_forecast_first_auction\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast first auction\",\n",
    "                line=dict(color=\"#fdb462\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=train_forecast_df.index,\n",
    "                y=train_forecast_df['price_second_auction_forecast'],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast second auction\",\n",
    "                line=dict(color=\"#80b1d3\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "            \n",
    "fig.update_layout(title='Normalized Training Actions Prices and Volumes')\n",
    "fig.update_yaxes(title='Price', row=1)\n",
    "fig.update_xaxes(title='Date', row=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILWIQbp07om-"
   },
   "source": [
    "# Plotting normalized test **prices** and **volume** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ehbc7nlp7vdW"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(\n",
    "            rows=2,\n",
    "            cols=2,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.08,\n",
    "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
    "            row_width=[0.2, 0.7],\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=normalized_test_auction.index,\n",
    "                y=normalized_test_auction[\"traded_volume_first_auction\"],\n",
    "                \n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=normalized_test_auction.index,\n",
    "                y=normalized_test_auction[\"traded_volume_second_auction\"],\n",
    "                \n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=normalized_test_auction.index,\n",
    "                y=normalized_test_auction[\"price_forecast_first_auction\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast first auction\",\n",
    "                line=dict(color=\"#fdb462\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=test_forecast_df.index,\n",
    "                y=test_forecast_df['price_second_auction_forecast'],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast second auction\",\n",
    "                line=dict(color=\"#80b1d3\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.update_layout(title='Normalized Test Actions Prices and Volumes', showlegend=True)\n",
    "fig.update_yaxes(title='Price', row=1)\n",
    "fig.update_xaxes(title='Date', row=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qm0jaSi9ZgDb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Getting the mean and standard deviation used during normalization\n",
    "mean = scaler.mean_[0]\n",
    "std = scaler.scale_[0]\n",
    "\n",
    "# Denormalizing the train forecast\n",
    "train_forecast_df['price_second_auction_forecast'] = train_forecast_df['price_second_auction_forecast'] * std + mean\n",
    "# Denormalizing the test forecast\n",
    "test_forecast_df['price_second_auction_forecast'] = test_forecast_df['price_second_auction_forecast'] * std + mean\n",
    "\n",
    "print(f\"train forecast df : {train_forecast_df['price_second_auction_forecast']}\")\n",
    "print(f\"test forecast df {test_forecast_df['price_second_auction_forecast']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbDHL_W8kaXX"
   },
   "source": [
    "#  Denormalized Plots: (Results) (train **prices** and **volume**) (test **prices** and **volume**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rYYqIgNorFOD"
   },
   "outputs": [],
   "source": [
    "# print(train_auction)\n",
    "# print(test_auction)\n",
    "\n",
    "fig = make_subplots()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=train_auction.index, y=train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
    "fig.add_trace(go.Scatter(x=train_forecast_df.index, y=train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.5)))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=test_auction.index, y=test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
    "fig.add_trace(go.Scatter(x=test_forecast_df.index, y=test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.5)))\n",
    "\n",
    "fig.update_layout(title='Denormalized Train and Test Forecasts Second Auction ')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Price')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeqI9bwaBIE6"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(\n",
    "            rows=2,\n",
    "            cols=2,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.08,\n",
    "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
    "            row_width=[0.2, 0.7],\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=train_auction.index, y=train_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price First Auction\", line=dict(color='#80b1d3')),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=train_auction.index, y=train_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\", name=\"Train Price Second Auction\", line=dict(color='#fb8072')),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=train_auction.index,\n",
    "                y=train_auction[\"traded_volume_first_auction\"],\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=train_auction.index,\n",
    "                y=train_auction[\"traded_volume_second_auction\"],\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=train_auction.index,\n",
    "                y=train_auction[\"price_forecast_first_auction\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast first auction\",\n",
    "                line=dict(color=\"#fdb462\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=train_forecast_df.index,\n",
    "                y=train_forecast_df['price_second_auction_forecast'],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast second auction\",\n",
    "                line=dict(color=\"#80b1d3\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "            \n",
    "fig.update_layout(title='Denormalized Training Actions Prices and Volumes')\n",
    "fig.update_yaxes(title='Price', row=1)\n",
    "fig.update_xaxes(title='Date', row=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItxmpoBbB6fB"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots(\n",
    "            rows=2,\n",
    "            cols=2,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.08,\n",
    "            subplot_titles=(\"1st Action Prices\", \"2nd Action Prices\", \"1st Action Volume\", \"2nd Action Volume\"),\n",
    "            row_width=[0.2, 0.7],\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=test_auction.index, y=test_auction[\"price_first_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price First Auction \", line=dict(color='#80b1d3')),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "fig.add_trace(\n",
    "            go.Scatter(x=test_auction.index, y=test_auction[\"price_second_auction\"], mode=\"lines\", line_shape=\"spline\",name=\"Test Price Second Auction\", line=dict(color='#fb8072')),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=test_auction.index,\n",
    "                y=test_auction[\"traded_volume_first_auction\"],\n",
    "                \n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=test_auction.index,\n",
    "                y=test_auction[\"traded_volume_second_auction\"],\n",
    "                \n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    opacity=1,\n",
    "                    line=dict(width=2, color=\"#ffffb3\"),\n",
    "                ),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=test_auction.index,\n",
    "                y=test_auction[\"price_forecast_first_auction\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast first auction\",\n",
    "                line=dict(color=\"#fdb462\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=test_forecast_df.index,\n",
    "                y=test_forecast_df['price_second_auction_forecast'],\n",
    "                mode=\"lines\",\n",
    "                name=\"Price train forecast second auction\",\n",
    "                line=dict(color=\"#80b1d3\", width=0.5),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=2,\n",
    "        )\n",
    "\n",
    "fig.update_layout(title='Denormalized Test Actions Prices and Volumes', showlegend=True)\n",
    "fig.update_yaxes(title='Price', row=1)\n",
    "fig.update_xaxes(title='Date', row=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jg57MthRdAv"
   },
   "source": [
    "# Tensor flow: predictions with Kfold validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGXyhmthgpd6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Split the input data into features and target\n",
    "train_features = normalized_train_auction.drop('price_second_auction', axis=1)\n",
    "train_target = normalized_train_auction['price_second_auction']\n",
    "# Concatenate the other datasets with the training features\n",
    "train_features = np.concatenate((train_features, normalized_train_forecast_inputs, normalized_train_system_prices), axis=1)\n",
    "\n",
    "# Define the number of folds for the K-fold cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "# Initialize a KFold object with the number of folds\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# Initialize arrays to store the results of the cross-validation\n",
    "cv_scores = []\n",
    "cv_histories = []\n",
    "\n",
    "# Loop over the folds\n",
    "for train_idx, val_idx in kfold.split(train_features):\n",
    "    # Split the data into training and validation sets for each fold\n",
    "    x_train, x_val = train_features[train_idx], train_features[val_idx]\n",
    "    y_train, y_val = train_target[train_idx], train_target[val_idx]\n",
    "    \n",
    "    # Build the neural network model using TensorFlow\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "    # Define callbacks to monitor the training process\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10),\n",
    "        ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=0.0001)\n",
    "    ]\n",
    "\n",
    "    # Reshape the data to include a channel dimension\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n",
    "    x_val = x_val.reshape(x_val.shape[0], x_val.shape[1], 1)\n",
    "\n",
    "    # Train the model on the training data for each fold\n",
    "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=callbacks)\n",
    "\n",
    "    # Evaluate the model on the validation data for each fold\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "\n",
    "    # Append the results of the fold to the arrays\n",
    "    cv_scores.append(score)\n",
    "    cv_histories.append(history)\n",
    "\n",
    "# Calculate the average performance of the model across all folds\n",
    "mean_score = np.mean(cv_scores, axis=0)\n",
    "\n",
    "# Print the average performance of the model\n",
    "print(\"Average performance on validation data:\")\n",
    "print(\"Loss: \", mean_score[0])\n",
    "print(\"Mean Absolute Error: \", mean_score[1])\n",
    "\n",
    "# Use the trained model to make predictions on the train data\n",
    "validated_train_forecast = model.predict(train_features)\n",
    "\n",
    "print(validated_train_forecast)\n",
    "print(validated_train_forecast.shape)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "test_features = normalized_test_auction.drop('price_second_auction', axis=1)\n",
    "\n",
    "# Concatenate the other datasets with the test features\n",
    "test_features = np.concatenate((test_features, normalized_test_forecast_inputs, normalized_test_system_prices), axis=1)\n",
    "\n",
    "validated_test_forecast = model.predict(test_features)\n",
    "\n",
    "\n",
    "# Summary: \n",
    "# The model being used is a 1D Convolutional Neural Network (CNN) built using TensorFlow. \n",
    "# It has multiple layers, including two 1D convolutional layers, two max pooling layers, a flatten layer, two dense layers, and a dropout layer. \n",
    "# It's trained using the Adam optimizer with a learning rate of 0.001 and the mean squared error (MSE) loss function. \n",
    "# It's also monitored using several callbacks, including EarlyStopping, ModelCheckpoint, and ReduceLROnPlateau. \n",
    "# Performming K-fold cross-validation, where the data is split into training and validation sets for each fold, and the model is trained and evaluated on each fold. \n",
    "# Finally, the trained model is used to make predictions on the train and test data.\n",
    "\n",
    "# Decided to change the model to CNN, one most commonly used for time series forecasting to validate and compare results with the previous model.\n",
    "# It is also recommended to do K-fold cross-validation in order to have a better performace estimation, reduce overfitting and helps us identifying \n",
    "# the model stability. If the performance scores low variability across different folds, it suggests that the model may perform well on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmeeFT69ZKvm"
   },
   "source": [
    "# Performance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeC8CGwfYL6F"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the mean and standard deviation of the target variable\n",
    "target_mean = np.mean(normalized_train_auction['price_second_auction'])\n",
    "target_std = np.std(normalized_train_auction['price_second_auction'])\n",
    "\n",
    "# Print the results\n",
    "print(\"Target Mean: \", target_mean)\n",
    "print(\"Target Standard Deviation: \", target_std)\n",
    "\n",
    "# Print the average performance of the model\n",
    "print(\"Average performance on validation data:\")\n",
    "print(\"Loss: \", mean_score[0])\n",
    "print(\"Mean Absolute Error: \", mean_score[1])\n",
    "\n",
    "# Based on the performance metrics, the model is performing relatively well. \n",
    "# The average loss value of 0.064 and mean absolute error value of 0.107 \n",
    "# It indicates that the model is making predictions that are relatively close to the true values, \n",
    "# with an average absolute difference of approximately 0.11 between the predicted and true values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T5lsVEqQkO-"
   },
   "source": [
    "# Results plot: Plotting validated normalized values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdlR8rJ9QibW"
   },
   "outputs": [],
   "source": [
    "print(validated_train_forecast)\n",
    "print(validated_test_forecast)\n",
    "\n",
    "# Creating a dataframe for the train forecast\n",
    "validated_train_forecast_df = pd.DataFrame(validated_train_forecast, index=normalized_train_auction.index, columns=['price_second_auction_forecast'])\n",
    "\n",
    "# Creating a dataframe for the test forecast\n",
    "validated_test_forecast_df = pd.DataFrame(validated_test_forecast, index=normalized_test_auction.index, columns=['price_second_auction_forecast'])\n",
    "\n",
    "fig = make_subplots()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
    "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
    "fig.add_trace(go.Scatter(x=validated_test_forecast_df.index, y=validated_test_forecast_df['price_second_auction_forecast'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
    "\n",
    "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Price')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FEVgWonvfvu"
   },
   "outputs": [],
   "source": [
    "start_date = pd.Timestamp('2022-02-28 23:00:00')\n",
    "end_date = pd.Timestamp('2022-09-12 23:00:00')\n",
    "\n",
    "# Calculate the number of hours between start_date and end_date\n",
    "n_hours = (end_date - start_date).total_seconds() / 3600\n",
    "\n",
    "print(\"Number of hours between start and end dates:\", n_hours)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9O8dUk1-aO_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices):\n",
    "    train_features = pd.concat([normalized_train_auction,\n",
    "                                  normalized_train_forecast_inputs,\n",
    "                                  normalized_train_system_prices], axis=1)\n",
    "    return train_features\n",
    "\n",
    "train_features = extract_features_from_past_data(normalized_train_auction, normalized_train_forecast_inputs, normalized_train_system_prices)\n",
    "# print(train_features)\n",
    "\n",
    "\n",
    "print(train_features.columns)\n",
    "print(f\"Train features lenght: {len(train_features)}\")\n",
    "print(f\"Train feauures shape : {train_features.shape}\")\n",
    "\n",
    "price_second_auction_index = train_features.columns.get_loc('price_second_auction')\n",
    "\n",
    "\n",
    "# Prepare input data for LSTM model\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "# Number of steps (hours) we want to predict into the future\n",
    "future = 196 * 24\n",
    "\n",
    "# Number of steps (in this case hours) we want to use to predict the future\n",
    "past = 30 * 24\n",
    "\n",
    "# Convert the train_features DataFrame to a NumPy array\n",
    "train_features_np = train_features.values\n",
    "\n",
    "price_second_auction_index = train_features.columns.get_loc('price_second_auction')\n",
    "\n",
    "for i in range(past, len(train_features_np) - future + 1):\n",
    "    x_train.append(train_features_np[i - past:i, 0:train_features.shape[1]])\n",
    "    y_train.append(train_features_np[i:i + future, price_second_auction_index])\n",
    "\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "print('x_train shape == {}.'.format(x_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(64, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(future))  # Output layer now predicts 'future' days at once\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(x_train, y_train, epochs=25, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkRZ7A9TGhVU"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aDHH2J4NGihl"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m n_days_for_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m196\u001b[39m  \u001b[38;5;66;03m# Predict 196 days\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming train_features has a DateTimeIndex\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m predict_period_dates \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mdate_range(train_features\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), periods\u001b[38;5;241m=\u001b[39mn_days_for_prediction, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(predict_period_dates)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Prepare the input data for the last n_days_for_prediction\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predicting...\n",
    "n_past = 30\n",
    "n_days_for_prediction = 196  # Predict 196 days\n",
    "\n",
    "# Assuming train_features has a DateTimeIndex\n",
    "predict_period_dates = pd.date_range(train_features.index[-1] + pd.Timedelta(days=1), periods=n_days_for_prediction, freq=\"D\").tolist()\n",
    "print(predict_period_dates)\n",
    "\n",
    "# Prepare the input data for the last n_days_for_prediction\n",
    "x_test = np.array([train_features[-n_past:].values])\n",
    "\n",
    "# Make predictions\n",
    "prediction = model.predict(x_test)  # shape = (1, 196), since we're predicting 196 days with the given model architecture\n",
    "\n",
    "# Create a temporary DataFrame with the same shape as the original data\n",
    "temp_df = pd.DataFrame(np.zeros((n_days_for_prediction, train_features.shape[1])), columns=train_features.columns)\n",
    "\n",
    "# Fill the first column with the predictions\n",
    "temp_df.iloc[:, 0] = prediction.flatten()\n",
    "\n",
    "# Perform inverse transformation to rescale back to original range\n",
    "y_pred_future = scaler.inverse_transform(temp_df)[:, 0]\n",
    "\n",
    "# Convert timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in predict_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "\n",
    "# Create a DataFrame with the forecast dates and predictions\n",
    "forecast_df = pd.DataFrame({'Date': forecast_dates, 'Prediction': y_pred_future})\n",
    "\n",
    "print(forecast_df)\n",
    "# Plot the predictions using Plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add a trace for the predictions\n",
    "fig.add_trace(go.Scatter(x=forecast_df['Date'], y=forecast_df['Prediction'], mode='lines', name='Predictions'))\n",
    "\n",
    "fig.update_layout(title='Future Price Predictions',\n",
    "                  xaxis_title='Date',\n",
    "                  yaxis_title='Price')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4L7po-797VqG"
   },
   "outputs": [],
   "source": [
    "\n",
    "fig = make_subplots()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_train_auction.index, y=normalized_train_auction['price_second_auction'], name='Train Price Second Auction', line=dict(color='#80b1d3')))\n",
    "fig.add_trace(go.Scatter(x=validated_train_forecast_df.index, y=validated_train_forecast_df['price_second_auction_forecast'], name='Train Price Second Auction Forecast', line=dict(color='#fdb462', width=0.8)))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=normalized_test_auction.index, y=normalized_test_auction['price_second_auction'], name='Test Price Second Auction', line=dict(color='#fb8072')))\n",
    "fig.add_trace(go.Scatter(x=forecast_df['Date'], y=forecast_df['Prediction'], name='Test Price Second Auction Forecast', line=dict(color='#8dd3c7', width=0.8)))\n",
    "\n",
    "fig.update_layout(title='Normalized Train and Test Forecasts Second Auction')\n",
    "fig.update_xaxes(title='Date')\n",
    "fig.update_yaxes(title='Price')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lgGD2y7-hZO_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chl_6A9XaTk5"
   },
   "source": [
    "# TRADING ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W84WOK1ramEL"
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def price_first_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Calculates the winning price and traded volume for each hour in a sealed bid auction.\n",
    "    In a sealed bid auction, all bids are submitted simultaneously and the highest bid wins.\n",
    "\n",
    "    Parameters:\n",
    "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
    "    \"\"\"\n",
    "    winning_prices = []\n",
    "    traded_volumes = []\n",
    "    for hourly_bids in bids:\n",
    "        if hourly_bids:\n",
    "            winning_price = max(bid[1] for bid in hourly_bids)\n",
    "            winning_prices.append(winning_price)\n",
    "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] == winning_price)\n",
    "            traded_volumes.append(traded_volume)\n",
    "        else:\n",
    "            winning_prices.append(0)\n",
    "            traded_volumes.append(0)\n",
    "    return (winning_prices, traded_volumes)\n",
    "\n",
    "def price_second_auction(bids: List[List[Tuple[int, int]]]) -> Tuple[List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Calculates the winning price and traded volume for each hour in a pay-as-bid auction.\n",
    "    In a pay-as-bid auction, bids are submitted one by one, and the current winning price is set to the highest bid so far.\n",
    "\n",
    "    Parameters:\n",
    "    bids (List[List[Tuple[int, int]]]): List of bids submitted by bidders for each hour of the next operating day\n",
    "\n",
    "    Returns:\n",
    "    Tuple[List[int], List[int]]: Winning price and traded volume for each hour\n",
    "    \"\"\"\n",
    "    winning_prices = []\n",
    "    traded_volumes = []\n",
    "    for hourly_bids in bids:\n",
    "        if hourly_bids:\n",
    "            winning_price = max(bid[1] for bid in hourly_bids)\n",
    "            winning_prices.append(winning_price)\n",
    "            traded_volume = sum(bid[0] for bid in hourly_bids if bid[1] >= winning_price)\n",
    "            traded_volumes.append(traded_volume)\n",
    "        else:\n",
    "            winning_prices.append(0)\n",
    "            traded_volumes.append(0)\n",
    "    return (winning_prices, traded_volumes)\n",
    "\n",
    "\n",
    "bids = [[(10, 20), (20, 30), (30, 25), (25, 20)]]\n",
    "\n",
    "winning_prices_first_auction = price_first_auction(bids)[0]\n",
    "traded_volumes_first_auction = price_first_auction(bids)[1]\n",
    "print(f\"Winning prices first auction : {winning_prices_first_auction}\")\n",
    "print(f\"Traded volumes first auction{traded_volumes_first_auction}\")\n",
    "\n",
    "winning_prices_second_auction = price_second_auction(bids)[0]\n",
    "traded_volumes_second_auction = price_second_auction(bids)[1]\n",
    "print(f\"Winning prices second auction : {winning_prices_second_auction}\")\n",
    "print(f\"Traded volumes second auction{traded_volumes_second_auction}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
